<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Principal Component Analysis - 2&nbsp; Methods</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./examples.html" rel="next">
<link href="./intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./methods.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Methods</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Principal Component Analysis</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./methods.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Examples</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dataset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./results.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Results</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./discussion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Discussion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./presentation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Presentation</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#assumptions" id="toc-assumptions" class="nav-link active" data-scroll-target="#assumptions"><span class="header-section-number">2.1</span> Assumptions</a></li>
  <li><a href="#preprocessing" id="toc-preprocessing" class="nav-link" data-scroll-target="#preprocessing"><span class="header-section-number">2.2</span> Preprocessing</a></li>
  <li><a href="#eigenvectors" id="toc-eigenvectors" class="nav-link" data-scroll-target="#eigenvectors"><span class="header-section-number">2.3</span> Eigenvectors</a></li>
  <li><a href="#principal-component-analysis" id="toc-principal-component-analysis" class="nav-link" data-scroll-target="#principal-component-analysis"><span class="header-section-number">2.4</span> Principal Component Analysis</a>
  <ul class="collapse">
  <li><a href="#centering-and-scaling" id="toc-centering-and-scaling" class="nav-link" data-scroll-target="#centering-and-scaling"><span class="header-section-number">2.4.1</span> Centering and Scaling</a></li>
  <li><a href="#eigendecomposition-of-the-covariance-matrix" id="toc-eigendecomposition-of-the-covariance-matrix" class="nav-link" data-scroll-target="#eigendecomposition-of-the-covariance-matrix"><span class="header-section-number">2.4.2</span> Eigendecomposition of the Covariance Matrix</a></li>
  <li><a href="#singular-value-decomposition" id="toc-singular-value-decomposition" class="nav-link" data-scroll-target="#singular-value-decomposition"><span class="header-section-number">2.4.3</span> Singular Value Decomposition</a></li>
  </ul></li>
  <li><a href="#interpretation-of-the-principal-components" id="toc-interpretation-of-the-principal-components" class="nav-link" data-scroll-target="#interpretation-of-the-principal-components"><span class="header-section-number">2.5</span> Interpretation of the Principal Components</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="methods" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Methods</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>The aim of Principal component analysis (PCA) is to reduce the dimensionality of multivariate data while preserving the variability present in the data. The principal components derived from the dataset are orthogonal variables represented by linear combinations of the original variables which maximize variance. The first principal component (PC) captures the most variance, followed by the second orthogonal principal component, and so on. There can be as many PCs as there are variables in the original data, but the technique is typically used to simplify high-dimension data for improved interpretability. Principal components can be calculated using eigenvalue decomposition or the singular value decomposition (SVD) of the data matrix, so data must be preproccesed and several assumptions met for PCA to yield meaningful results.</p>
<section id="assumptions" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="assumptions"><span class="header-section-number">2.1</span> Assumptions</h2>
<p>For PCA to be effective, the data should be continuous (although adaptations of PCA exist for other numeric data structures) and normally distributed, although the the distribution of the data does not truly matter when utilizing PCA as an exploratory methodology. More importantly, the data should be linearly related or the linear combinations of the principal components cannot meaningfully capture the variance of the data. Ideally, the variables should be similar in scale, and free from extreme outliers, or missing values, although this can be addressed in preprocessing, and implementations of PCA such as robust PCA have been developed to address these challenges. <span class="citation" data-cites="jolliffe2016principal"><a href="references.html#ref-jolliffe2016principal" role="doc-biblioref">[1]</a></span></p>
</section>
<section id="preprocessing" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="preprocessing"><span class="header-section-number">2.2</span> Preprocessing</h2>
<p>Preprocessing data for PCA is straightforward. Missing data should be handled using a method appropriate for the dataset, such as imputation based on the mean or median of the variable observations. After this the variables should be centered and scaled, to a mean of 0 and a standard deviation of 1, although statistical software libraries for SVD and PCA may include this as an option within the function. <span class="citation" data-cites="prcomp2023ref"><a href="references.html#ref-prcomp2023ref" role="doc-biblioref">[2]</a></span></p>
</section>
<section id="eigenvectors" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="eigenvectors"><span class="header-section-number">2.3</span> Eigenvectors</h2>
<p>PCA uses eigenvectors and their corresponding eigenvalues to calculate the principal components; a brief overview is given here. Eigen is a German word meaning <em>inherent</em> or <em>characteristic</em>, and an eigenvector can be described geometrically as a nonzero vector <span class="math inline">\(a\)</span> of a linear transformation matrix <span class="math inline">\(M\)</span> which does not change direction when the transformation is applied; the only change that occurs is a scaling by factor <span class="math inline">\(\lambda\)</span>, the eigenvalue of the eigenvector <span class="math inline">\(a\)</span>. Such a characteristic vector is useful in PCA, where the goal is to maximize variance while reducing dimensionality, and in this context the eigenvectors and eigenvalues can be thought of as the inherent components of the dataset which contain the most important information. Eigenvalues can be calculated from the characteristic polynomial of the matrix, by taking the determinant of <span class="math inline">\(M - \lambda I\)</span>, where <span class="math inline">\(I\)</span> is the identity matrix. Setting this expression equal to zero allows the calculation of the eigenvalues as the roots of the characteristic polynomial; the resulting equation is called the characteristic equation:</p>
<p><span id="eq-1"><span class="math display">\[
det(M - \lambda I) = 0
\tag{2.1}\]</span></span></p>
<p>An eigenvalue <span class="math inline">\(\lambda_k\)</span> can be used to solve for some eigenvector <span class="math inline">\(a_k\)</span> with the equation <span class="math inline">\((M - \lambda I)a = 0\)</span>. With PCA, we can use the eigenvectors of the covariance matrix to compute the PCs. <span class="citation" data-cites="bennett2021linear"><a href="references.html#ref-bennett2021linear" role="doc-biblioref">[3]</a></span></p>
</section>
<section id="principal-component-analysis" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="principal-component-analysis"><span class="header-section-number">2.4</span> Principal Component Analysis</h2>
<p>In this approach to PCA, SVD is used to extract the most information (variance) from the data matrix while reducing the dimensionality of the data. The first principal component will have the largest possible variance (also called inertia), whose value is defined as a factor score. Factor scores represent a geometric projection of the observations onto the PCs. The second PC, orthogonal to the first, has the second largest variance, and the third PC would continue this pattern. The calculation of PCs via SVD can be understood with the use of matrix operations on a dataset. <span class="citation" data-cites="hopcroft2014foundations"><a href="references.html#ref-hopcroft2014foundations" role="doc-biblioref">[4]</a></span></p>
<section id="centering-and-scaling" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="centering-and-scaling"><span class="header-section-number">2.4.1</span> Centering and Scaling</h3>
<p>Let our dataset be represented by the <span class="math inline">\(N \times P\)</span> matrix <span class="math inline">\(X\)</span> comprised of <span class="math inline">\(N\)</span> observations of <span class="math inline">\(P\)</span> variables in the data set, where any element <span class="math inline">\(x_{np}\)</span> represents the <span class="math inline">\(n\)</span>th observation of variable <span class="math inline">\(p\)</span> in the dataset. The matrix <span class="math inline">\(X\)</span> has rank <span class="math inline">\(A\)</span> where <span class="math inline">\(A \leq min\{N, P\}\)</span>. The data in <span class="math inline">\(X\)</span> is centered and scaled, such that the mean of each column <span class="math inline">\(X_p\)</span> is 0 and every <span class="math inline">\(x_{np}\)</span> has been standardized with unit variance. We can represent this with the formula:</p>
<p><span id="eq-2"><span class="math display">\[
z_{np} = \frac{x_{np} - \bar{x}_{p}}{{\sigma_{p}}}
\tag{2.2}\]</span></span></p>
</section>
<section id="eigendecomposition-of-the-covariance-matrix" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="eigendecomposition-of-the-covariance-matrix"><span class="header-section-number">2.4.2</span> Eigendecomposition of the Covariance Matrix</h3>
<p>The aim of PCA is to find some linear combination of the columns of <span class="math inline">\(X\)</span> which maximizes the variance. If we define <span class="math inline">\(a\)</span> as a vector of constants <span class="math inline">\(a_1, a_2, a_3, …, a_p\)</span>, then <span class="math inline">\(Xa\)</span> represents the linear combination of interest. The variance of <span class="math inline">\(Xa\)</span> is represented by <span class="math inline">\(var(Xa) = a^TSa\)</span>, with the covariance matrix <span class="math inline">\(S\)</span>, and <span class="math inline">\(T\)</span> representing the transpose operator. Finding the <span class="math inline">\(Xa\)</span> with maximum variance equates to finding the vector <span class="math inline">\(a\)</span> which maximizes the quadratic <span class="math inline">\(a^TSa\)</span>, where <span class="math inline">\(a^Ta = 1\)</span>. We can write this as <span class="math inline">\(a^TSa - \lambda(a^Ta-1)\)</span>, with the Lagrange multiplier <span class="math inline">\(\lambda\)</span>. <span class="citation" data-cites="luenberger1997optimization"><a href="references.html#ref-luenberger1997optimization" role="doc-biblioref">[5]</a></span> Equating this expression to the null vector <span class="math inline">\(0\)</span> allows us to differentiate with respect to <span class="math inline">\(a\)</span>:</p>
<p><span id="eq-3"><span class="math display">\[
Sa - \lambda a = 0 \Rightarrow Sa = \lambda a
\tag{2.3}\]</span></span></p>
<p>Therefore, <span class="math inline">\(a\)</span> is a unit-norm eigenvector with eigenvalue <span class="math inline">\(\lambda\)</span> of the covariance matrix <span class="math inline">\(S\)</span>. The largest eigenvalue of <span class="math inline">\(S\)</span> is <span class="math inline">\(\lambda_1\)</span> with the eigenvector <span class="math inline">\(a_1\)</span>, which we can define for any eigenvector <span class="math inline">\(a\)</span>:</p>
<p><span id="eq-4"><span class="math display">\[
var(Xa) = a^TSa = \lambda a^Ta = \lambda
\tag{2.4}\]</span></span></p>
<p>Any <span class="math inline">\(p \times p\)</span> real symmetric matrix has exactly <span class="math inline">\(p\)</span> real eigenvalues <span class="math inline">\(\lambda_k\)</span> for <span class="math inline">\(k = 1,...,p\)</span>. The corresponding eigenvectors of these eigenvalues can be defined to form an orthonormal set of vectors such that <span class="math inline">\(a_k^Ta_{k^T} = 1\)</span> if <span class="math inline">\(k = k^T\)</span> and zero otherwise. If we consider that <span class="math inline">\(S\)</span> is such a matrix and impose the restriction of orthogonality to the different coefficient vectors of <span class="math inline">\(S\)</span>, the full set of eigenvectors of <span class="math inline">\(S\)</span> represent the solutions to finding linear combinations <span class="math inline">\(Xa_k\)</span> which maximize variance while minimizing correlation with prior linear combinations. <span class="math inline">\(Xa_k\)</span> then represent the linear combinations which are the principal components of the dataset with eigenvectors <span class="math inline">\(a_k\)</span> and eigenvalues <span class="math inline">\(\lambda_k\)</span>. The elements of <span class="math inline">\(Xa_k\)</span> are the factor scores of the PCs, while the elements of the eigenvectors <span class="math inline">\(a_k\)</span> represent the loadings of the PCs. <span class="citation" data-cites="jolliffe2016principal"><a href="references.html#ref-jolliffe2016principal" role="doc-biblioref">[1]</a></span></p>
</section>
<section id="singular-value-decomposition" class="level3" data-number="2.4.3">
<h3 data-number="2.4.3" class="anchored" data-anchor-id="singular-value-decomposition"><span class="header-section-number">2.4.3</span> Singular Value Decomposition</h3>
<p>Next we define the singular value decomposition of <span class="math inline">\(X\)</span>. Let <span class="math inline">\(L\)</span> be the <span class="math inline">\(N \times A\)</span> matrix of left singular vectors of the matrix; that is, the columns of <span class="math inline">\(L\)</span> are made up of the eigenvectors of <span class="math inline">\(XX^T\)</span>. Let <span class="math inline">\(R\)</span> be the <span class="math inline">\(P \times A\)</span> matrix of right singular vectors; the columns of <span class="math inline">\(R\)</span> are made up of the eigenvectors of <span class="math inline">\(X^TX\)</span>. Finally, let <span class="math inline">\(D\)</span> be the diagonal matrix of singular values, meaning the singular values in <span class="math inline">\(D\)</span> are the square roots of the eigenvalues of <span class="math inline">\(XX^T\)</span> and <span class="math inline">\(X^TX\)</span>, and <span class="math inline">\(D^2\)</span> is defined as the diagonal matrix of the non-zero eigenvalues. We can define the singular value decomposition of matrix <span class="math inline">\(X\)</span> as:</p>
<p><span id="eq-5"><span class="math display">\[
X = LD{R}^T
\tag{2.5}\]</span></span></p>
<p>In this context, the eigenvalues represent the variances of the principal components and summarily contain the important information for the dataset, and we can obtain the PCs of <span class="math inline">\(X\)</span> from the SVD. <span class="citation" data-cites="abdi2010principal"><a href="references.html#ref-abdi2010principal" role="doc-biblioref">[6]</a></span> With the identity matrix <span class="math inline">\(I\)</span>, the <span class="math inline">\(I \times R\)</span> matrix of factor scores can be expressed as:</p>
<p><span id="eq-6"><span class="math display">\[
F = LD
\tag{2.6}\]</span></span></p>
<p>These factor scores are calculated from the coefficients of the linear combinations in matrix <span class="math inline">\(R\)</span>, which can be defined as a projection matrix of the original observations onto the PCs, i.e.&nbsp;the product of <span class="math inline">\(X\)</span> and <span class="math inline">\(R\)</span>:</p>
<p><span id="eq-7"><span class="math display">\[
F = LD = LDR^TR = XR
\tag{2.7}\]</span></span></p>
<p>The matrix <span class="math inline">\(R\)</span> is also referred to as a loading matrix, and <span class="math inline">\(X\)</span> is often described as the product of the factor score matrix and the loading matrix:</p>
<p><span id="eq-8"><span class="math display">\[
X = FR^T
\tag{2.8}\]</span></span></p>
<p>with the decomposition of <span class="math inline">\(F^TF = D^2\)</span> and <span class="math inline">\(R^TR = I\)</span>.</p>
<p>The loadings represent the weights of the original variables in the computation of the PCs; in other words, the correlation from -1 to 1 of each variable with the factor score.</p>
<p>In a geometric interpretation of PCA, the factor scores measure length on the Cartesian plane. This length represents the projection of the original observations onto the PCs from the origin at <span class="math inline">\((0, 0)\)</span>. This is especially useful as a visualization of higher dimension data in two dimensions by utilizing the first two PCs which capture the most variance in the original data. <span class="citation" data-cites="lever2017points"><a href="references.html#ref-lever2017points" role="doc-biblioref">[7]</a></span></p>
</section>
</section>
<section id="interpretation-of-the-principal-components" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="interpretation-of-the-principal-components"><span class="header-section-number">2.5</span> Interpretation of the Principal Components</h2>
<p>There are several ways to interpret the PCs derived from the analysis. Since the eigenvalues represent the variance of the PCs, the proportion of the eigenvalues explain the proportion of variation in the dataset. Using a scree plot, these eigenvalues are plotted to show how much variation each PC explains. Another commonly used tool is a biplot, a combination of the plots of the factor scores (points) and the loadings (vectors) for two PCs (typically PC1 and PC2). The biplot is meant to visually capture the relationship between the original variables and the principal components. Clusters of points represent highly correlated variables, and vector lengths represent the variability captured in that direction on the principal component axis. While many methods and tools exist to interpret the results of PCA, the usefulness of each depends on the needs of the analysis. <span class="citation" data-cites="bennett2021linear"><a href="references.html#ref-bennett2021linear" role="doc-biblioref">[3]</a></span></p>


<div id="refs" class="references csl-bib-body" role="list" style="display: none">
<div id="ref-jolliffe2016principal" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">I. T. Jolliffe and J. Cadima, <span>“Principal component analysis: A review and recent developments,”</span> <em>Philosophical transactions of the royal society A: Mathematical, Physical and Engineering Sciences</em>, vol. 374, no. 2065, p. 20150202, 2016.</div>
</div>
<div id="ref-prcomp2023ref" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">R Core Team, <span>“Prcomp, a function of r: A language and environment for statistical computing.”</span> R Foundation for Statistical Computing, Vienna, Austria, 2023. Available: <a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/prcomp">https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/prcomp</a>. [Accessed: Oct. 16, 2023]</div>
</div>
<div id="ref-bennett2021linear" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">S. R. Bennett, <span>“Linear algebra for data science.”</span> 2021. Available: <a href="https://shainarace.github.io/LinearAlgebra/index.html">https://shainarace.github.io/LinearAlgebra/index.html</a>. [Accessed: Oct. 16, 2023]</div>
</div>
<div id="ref-hopcroft2014foundations" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">J. Hopcroft and R. Kannan, <em>Foundations of data science</em>. 2014.</div>
</div>
<div id="ref-luenberger1997optimization" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">D. G. Luenberger, <em>Optimization by vector space methods</em>. John Wiley &amp; Sons, 1997.</div>
</div>
<div id="ref-abdi2010principal" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">H. Abdi and L. J. Williams, <span>“Principal component analysis,”</span> <em>WIREs Computational Statistics</em>, vol. 2, no. 4, pp. 433–459, 2010, doi: <a href="https://doi.org/10.1002/wics.101">https://doi.org/10.1002/wics.101</a>. Available: <a href="https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wics.101">https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wics.101</a></div>
</div>
<div id="ref-lever2017points" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">J. Lever, M. Krzywinski, and N. Altman, <span>“Points of significance: Principal component analysis,”</span> <em>Nature methods</em>, vol. 14, no. 7, pp. 641–643, 2017.</div>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./intro.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./examples.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Examples</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>