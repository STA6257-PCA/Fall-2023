<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Principal Component Analysis - 1&nbsp; Introduction</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./methods.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./intro.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Principal Component Analysis</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Examples</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dataset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./results.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Results</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./discussion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Discussion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./presentation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Presentation</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#theoretical-and-mathematical-foundations" id="toc-theoretical-and-mathematical-foundations" class="nav-link active" data-scroll-target="#theoretical-and-mathematical-foundations"><span class="header-section-number">1.1</span> Theoretical and mathematical foundations</a></li>
  <li><a href="#applications-and-extensions" id="toc-applications-and-extensions" class="nav-link" data-scroll-target="#applications-and-extensions"><span class="header-section-number">1.2</span> Applications and extensions</a>
  <ul class="collapse">
  <li><a href="#in-archeology-neuroscience-and-the-arts" id="toc-in-archeology-neuroscience-and-the-arts" class="nav-link" data-scroll-target="#in-archeology-neuroscience-and-the-arts"><span class="header-section-number">1.2.1</span> In Archeology, Neuroscience, and the Arts</a></li>
  <li><a href="#computer-vision-and-pattern-recognition" id="toc-computer-vision-and-pattern-recognition" class="nav-link" data-scroll-target="#computer-vision-and-pattern-recognition"><span class="header-section-number">1.2.2</span> Computer Vision and Pattern Recognition</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="intro" class="quarto-section-identifier"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>In recent years, the exponential growth of large datasets with numerous variables have become increasingly prevalent across various fields <span class="citation" data-cites="ringner2008principal"><a href="references.html#ref-ringner2008principal" role="doc-biblioref">[1]</a></span>, including but not limited to data analysis, image processing, genetics, finance, and signal processing <span class="citation" data-cites="jolliffe2016principal"><a href="references.html#ref-jolliffe2016principal" role="doc-biblioref">[2]</a></span>. Analyzing, processing, and visualizing these multivariate datasets pose significant challenges. Therefore, the significance of unsupervised learning algorithms comes into play, particularly in tasks like dimensionality reduction, feature extraction, and visualization of complex data sets. Unsupervised learning is a collection of algorithms to classify raw data <span class="citation" data-cites="esposito2020introducing"><a href="references.html#ref-esposito2020introducing" role="doc-biblioref">[3]</a></span>. Clustering, and density estimation methods, often serve as a crucial preliminary step in dimensionality reduction where the objective is to find patterns and correlations aiding in organizing the original data. The underlying structures and relationships within the data can inform the selection and application of dimensionality reduction techniques.</p>
<p>Moreover, dimensionality reduction (DR) techniques aim to mitigate the challenge of extracting valuable insights from complex data by reducing the number of dimensions, decreasing computational complexity, eliminating irrelevant and redundant data, improving algorithm accuracy, and facilitating efficient data visualization <span class="citation" data-cites="hasan2021review"><a href="references.html#ref-hasan2021review" role="doc-biblioref">[4]</a></span>. Unsupervised learning and dimensionality reduction are indispensable tools in data analysis, and machine learning. While unsupervised learning aims to uncover patterns and correlations between raw data, dimensionality reduction simplifies data representation. One widely used DR technique is Principal Component Analysis (PCA). The objectives of the present research project are the comprehensive exploration of PCA, encompassing an introduction to its core concepts, a discussion of its purposes and functions as well as a demonstration of its application through step-by-step examples.</p>
<p>Principal Component Analysis is best described as a dimension reduction technique for statistical data. PCA has its roots in the work of Karl Pearson in his 1901 paper “On Lines and Planes of Closest Fit to Systems of Points in Space” <span class="citation" data-cites="pearson1901liii"><a href="references.html#ref-pearson1901liii" role="doc-biblioref">[5]</a></span> with the later christening and formal development of the technique by Harold Hotelling in 1933 <span class="citation" data-cites="hotelling1933analysis"><a href="references.html#ref-hotelling1933analysis" role="doc-biblioref">[6]</a></span>. Pearson initially conceptualized PCA as a geometric interpretation within statistics; subsequently, PCA gained recognition as a more suitable method than analysis of variance for modeling response data <span class="citation" data-cites="fisher1923studies"><a href="references.html#ref-fisher1923studies" role="doc-biblioref">[7]</a></span>. The aim of PCA is to reduce the dimensionality of a dataset without loss of information about the variability of the data. By creating principal components that act as analogues for variables, the statistical information of the dataset can be preserved and compressed into a more easily representable form. A common example of the application of PCA involves reducing an n-dimensional data set into 2 principal components which can be plotted on a graph representing the relationships among the original variables; for this reason, PCA is often described as an exploratory data analysis tool.</p>
<section id="theoretical-and-mathematical-foundations" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="theoretical-and-mathematical-foundations"><span class="header-section-number">1.1</span> Theoretical and mathematical foundations</h2>
<p>The fundamental concept behind PCA is to explain the variability in a set of correlated variables with a smaller set of uncorrelated variables, thus mitigating issues such as multicollinearity. The geometric properties of PCs facilitate an intuitive interpretation of key features within complex multivariate datasets <span class="citation" data-cites="greenacre2022principal"><a href="references.html#ref-greenacre2022principal" role="doc-biblioref">[8]</a></span>; the first principal component represents the direction with the greatest variation in the original data, while subsequent components are uncorrelated with the previous ones. Each component can be interpreted as the direction that maximizes the variance of the original data when projecting new observations onto the components <span class="citation" data-cites="ringner2008principal"><a href="references.html#ref-ringner2008principal" role="doc-biblioref">[1]</a></span>. PCA aims to capture a significant proportion of the original variables’ variation in the first few components, offering a practical lower-dimensional summary. While other methods may involve weighted averages across related variables to reduce dimensions, PCA often achieves similar results with minimal loss of variance information <span class="citation" data-cites="everitt2011introduction"><a href="references.html#ref-everitt2011introduction" role="doc-biblioref">[9]</a></span>. The mathematical foundations of PCA center around data of <span class="math inline">\(p\)</span> variables in <span class="math inline">\(n\)</span> observations, represented by an <span class="math inline">\(n \times p\)</span> matrix <span class="math inline">\(X\)</span> with the goal of finding a linear combination of the columns of <span class="math inline">\(X\)</span> which maximize variance. By maximizing the variance in these linear combinations, we can capture the largest amount of statistical information possible among the dimensions of the dataset. As described by Jolliffe and Cadima <span class="citation" data-cites="jolliffe2016principal"><a href="references.html#ref-jolliffe2016principal" role="doc-biblioref">[2]</a></span>, this boils down to finding the eigenvectors (<span class="math inline">\(a\)</span>) and the largest eigenvalues (<span class="math inline">\(\lambda\)</span>) of the covariance matrix <span class="math inline">\(S\)</span>, where <span class="math inline">\(Xa_k\)</span> are the linear combinations called the principal components.</p>
<p>With the development of software packages in computer languages such as R and Python, the computational burden of PCA for large datasets can be easily handled by software; PCA has become easy to use as part of any data processing pipeline. Abdi and Williams describe PCA as “probably the most popular multivariate statistical technique … used by almost all scientific disciplines.” <span class="citation" data-cites="abdi2010principal"><a href="references.html#ref-abdi2010principal" role="doc-biblioref">[10]</a></span> Abdi and Williams also emphasize that the goals of PCA should be extracting only the most important information from a dataset to both compress and simplify the dataset and provide a way to analyze the structure of the observations and variables more easily. Importantly, the authors also offer a geometric description of the principal components as orthogonal factors to the original axis of the dataset; another strength of PCA is the fact that the technique can be explained and expressed through several mathematical avenues. Finally, Abdi and Williams offer methods to evaluate the quality of the “PCA model” in reconstructing the original data matrix using the derived principal components. For example, calculating the residual sum of squares, or RESS, after rebuilding X provides a way to identify model accuracy by seeking a minimal RESS value from X and X.&nbsp;</p>
<p>Lever and Altman <span class="citation" data-cites="lever2017points"><a href="references.html#ref-lever2017points" role="doc-biblioref">[11]</a></span> offer similar praises of PCA while echoing the cautions of prior authors as a powerful data exploration tool with clear limitations. PCA is best when interesting patterns in data produce statistical variance which can be capture by the principal components, but the technique is far less effective when patterns in data are non-linear or non-orthogonal or when the maximization of variance fails to produce interesting clusters in the principal component space. Scaling is often necessary for PCA to ensure compatibility across variables with different scales and ranges. The original data is typically standardized to have a mean of 0 and a variance of 1 <span class="citation" data-cites="greenacre2022principal"><a href="references.html#ref-greenacre2022principal" role="doc-biblioref">[8]</a></span>. PCA can be used improperly to produce results that obfuscate the actual statistical content of the dataset; scaling may influence the analysis with prior knowledge of the data, so the decision to scale the data and the scaling methodology should be considered carefully.</p>
</section>
<section id="applications-and-extensions" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="applications-and-extensions"><span class="header-section-number">1.2</span> Applications and extensions</h2>
<section id="in-archeology-neuroscience-and-the-arts" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="in-archeology-neuroscience-and-the-arts"><span class="header-section-number">1.2.1</span> In Archeology, Neuroscience, and the Arts</h3>
<p>PCA has been utilized by many authors across numerous fields as an essential part of a data analysis pipeline. As an example of the application of PCA, Jolliffe and Cadima <span class="citation" data-cites="jolliffe2016principal"><a href="references.html#ref-jolliffe2016principal" role="doc-biblioref">[2]</a></span> present a dataset of 88 observations with 9 variables of measurement for fossilized mammal teeth including length in two dimensions, width in two dimensions, and more. With the R statistical language, finding and displaying the principal components of the dataset becomes trivial work where patterns can be identified graphically in a two-dimensional (PC1 x PC2) plot, versus the original scatterplot which would be displayed in nine-dimensional space. The development of statistical software has made it straightforward for practitioners to use PCA for data exploration and dimensionality reduction. Authors such as Maindonald and Braun <span class="citation" data-cites="maindonald2006data"><a href="references.html#ref-maindonald2006data" role="doc-biblioref">[12]</a></span> have produced publications which present techniques and step-by-step methodologies of using R to calculate principal components and graphically display the results. Their presentation includes code snippets which can be run in R software environments along with worked examples and a discussion of results, facilitating the use of the technique for practitioners of all experience levels.</p>
<p>Felipe Gewers and their research team directly expound on Abdi and Williams’ description of PCA as “the most popular multivariate statistical technique [...]” in an analysis of publications which use PCA: Across twenty-three disciplines ranging from Neuroscience to the Arts, PCA is used to explore a dataset before analysis, used as part of a spectrum of statistical analysis tools prior to modeling and analysis, or used to preprocess and simplify data for direct analysis and modeling <span class="citation" data-cites="gewers2021principal"><a href="references.html#ref-gewers2021principal" role="doc-biblioref">[13]</a></span>. The authors also discuss the broad effectiveness of PCA in representing more than 50% of the variance in most datasets using only the first three principal components. They also highlight how differences in captured variance appear between standardization and non-standardization, and in different fields of study; PCA can be effective in an incredibly diverse array of data when applied appropriately. As an exploratory technique with a long tenure in the field of statistics and data analysis, PCA is tried and true in simplifying datasets and allowing practitioners to identify and explore the largest sources of statistical information present in their data.</p>
<p>Principal Component Analysis is also implemented in Scikit Learn with randomized Singular Value Decomposition (SVD) for dimensionality reduction in data analysis, particularly for face recognition and similar high-dimensional data applications. For instance, with an image of 4096 dimensions (64x64 pixel gray scale images) PCA can transform the data into a lower 200 dimension format that still captures the essential information <span class="citation" data-cites="pedregosa2011scikit"><a href="references.html#ref-pedregosa2011scikit" role="doc-biblioref">[14]</a></span>. With randomized SVD it becomes computationally more efficient to approximate the singular vectors, which are then used to perform the transformation. This approach significantly reduces computation time and memory usage. Additionally, PCA decomposes a multivariate dataset into orthogonal components that explain the maximum amount of variance. It can center and optionally scale the input data before applying SVD. Scaling can be useful for downstream models, such as Support Vector Machines with the RBF kernel and K-Means clustering, which assume certain properties of the data distribution.</p>
</section>
<section id="computer-vision-and-pattern-recognition" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="computer-vision-and-pattern-recognition"><span class="header-section-number">1.2.2</span> Computer Vision and Pattern Recognition</h3>
<p>The Eigenfaces concept has emerged as a groundbreaking approach to facial detection and recognition. The Eigenfaces algorithm employs PCA to extract essential facial features, reducing the dimensionality of face images while retaining crucial information. The Eigenfaces technique represents facial images in high-dimensional space while projecting the images onto a lower-dimensional space. Turk and Pentland demonstrated the effectiveness of Eigenfaces in recognizing faces under various conditions, including variations in lighting, facial expressions, and pose <span class="citation" data-cites="turk1991eigenfaces"><a href="references.html#ref-turk1991eigenfaces" role="doc-biblioref">[15]</a></span>. The potential implications of this research extend beyond face recognition, and have broader implications for image analysis, computer vision, and biometric systems. The paper Eigenfaces by Zhang and Turk provided an insightful exploration of the Eigenfaces method <span class="citation" data-cites="zhang2008eigenfaces"><a href="references.html#ref-zhang2008eigenfaces" role="doc-biblioref">[16]</a></span>, considered as the first working technique in facial recognition. Eigenfaces leverage the power of PCA to represent facial images compactly and efficiently, making it possible to recognize faces in various contexts.</p>
<p>The idea of principal components to represent human faces was developed by Sirovich and Kirby in 1987 and used by Turk and Pentland in 1991 <span class="citation" data-cites="turk1991eigenfaces"><a href="references.html#ref-turk1991eigenfaces" role="doc-biblioref">[15]</a></span> for face detection and recognition. The authors describe the mathematical principles behind PCA, and its adaptation for facial recognition, capturing the most prominent facial features while reducing the dimensionality of the data. Specifically, the eigenfaces are the principal components of a distribution of faces, or the eigenvectors of the covariance matrix of the set of face images, where an image with N pixels is considered a point (or vector) in N-dimensional space. Emphasis is placed on the versatility of Eigenfaces in handling variations in lighting, pose, and facial expressions, making it a robust tool for real-world applications.</p>
<p>This application of PCA represents one of many for a longstanding technique in the rapidly growing field of statistics and data analysis. The unsupervised learning algorithm plays a vital role in dimensionality reduction, feature extraction, and visualization of complex data sets. Understanding PCA is crucial for researchers, and students seeking to extract meaningful insights and patterns from high-dimensional data to simplify the decision-making process.</p>


<div id="refs" class="references csl-bib-body" role="list" style="display: none">
<div id="ref-ringner2008principal" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">M. Ringnér, <span>“What is principal component analysis?”</span> <em>Nature biotechnology</em>, vol. 26, no. 3, pp. 303–304, 2008.</div>
</div>
<div id="ref-jolliffe2016principal" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">I. T. Jolliffe and J. Cadima, <span>“Principal component analysis: A review and recent developments,”</span> <em>Philosophical transactions of the royal society A: Mathematical, Physical and Engineering Sciences</em>, vol. 374, no. 2065, p. 20150202, 2016.</div>
</div>
<div id="ref-esposito2020introducing" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">D. Esposito and F. Esposito, <em>Introducing machine learning</em>. Microsoft Press, 2020.</div>
</div>
<div id="ref-hasan2021review" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">B. M. S. Hasan and A. M. Abdulazeez, <span>“A review of principal component analysis algorithm for dimensionality reduction,”</span> <em>Journal of Soft Computing and Data Mining</em>, vol. 2, no. 1, pp. 20–30, 2021.</div>
</div>
<div id="ref-pearson1901liii" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">K. Pearson, <span>“LIII. On lines and planes of closest fit to systems of points in space,”</span> <em>The London, Edinburgh, and Dublin philosophical magazine and journal of science</em>, vol. 2, no. 11, pp. 559–572, 1901.</div>
</div>
<div id="ref-hotelling1933analysis" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">H. Hotelling, <span>“Analysis of a complex of statistical variables into principal components.”</span> <em>Journal of educational psychology</em>, vol. 24, no. 6, p. 417, 1933.</div>
</div>
<div id="ref-fisher1923studies" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">R. A. Fisher and W. A. Mackenzie, <span>“Studies in crop variation. II. The manurial response of different potato varieties,”</span> <em>The Journal of Agricultural Science</em>, vol. 13, no. 3, pp. 311–320, 1923.</div>
</div>
<div id="ref-greenacre2022principal" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">M. Greenacre, P. J. Groenen, T. Hastie, A. I. d’Enza, A. Markos, and E. Tuzhilina, <span>“Principal component analysis,”</span> <em>Nature Reviews Methods Primers</em>, vol. 2, no. 1, p. 100, 2022.</div>
</div>
<div id="ref-everitt2011introduction" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">B. Everitt and T. Hothorn, <em>An introduction to applied multivariate analysis with r</em>. Springer Science &amp; Business Media, 2011.</div>
</div>
<div id="ref-abdi2010principal" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">H. Abdi and L. J. Williams, <span>“Principal component analysis,”</span> <em>WIREs Computational Statistics</em>, vol. 2, no. 4, pp. 433–459, 2010, doi: <a href="https://doi.org/10.1002/wics.101">https://doi.org/10.1002/wics.101</a>. Available: <a href="https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wics.101">https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wics.101</a></div>
</div>
<div id="ref-lever2017points" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">J. Lever, M. Krzywinski, and N. Altman, <span>“Points of significance: Principal component analysis,”</span> <em>Nature methods</em>, vol. 14, no. 7, pp. 641–643, 2017.</div>
</div>
<div id="ref-maindonald2006data" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">J. Maindonald and J. Braun, <em>Data analysis and graphics using r: An example-based approach</em>, vol. 10. Cambridge University Press, 2006.</div>
</div>
<div id="ref-gewers2021principal" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">F. L. Gewers <em>et al.</em>, <span>“Principal component analysis: A natural approach to data exploration,”</span> <em>ACM Computing Surveys (CSUR)</em>, vol. 54, no. 4, pp. 1–34, 2021.</div>
</div>
<div id="ref-pedregosa2011scikit" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">F. Pedregosa <em>et al.</em>, <span>“Scikit-learn: Machine learning in python,”</span> <em>the Journal of machine Learning research</em>, vol. 12, pp. 2825–2830, 2011.</div>
</div>
<div id="ref-turk1991eigenfaces" class="csl-entry" role="listitem">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">M. Turk and A. Pentland, <span>“Eigenfaces for recognition,”</span> <em>Journal of cognitive neuroscience</em>, vol. 3, no. 1, pp. 71–86, 1991.</div>
</div>
<div id="ref-zhang2008eigenfaces" class="csl-entry" role="listitem">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline">S. Zhang and M. Turk, <span>“Eigenfaces,”</span> <em>Scholarpedia</em>, vol. 3, no. 9, p. 4244, 2008.</div>
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Home</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./methods.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Methods</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>