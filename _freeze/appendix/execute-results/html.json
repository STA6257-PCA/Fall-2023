{
  "hash": "123d287ed8dfd35d698cfc64f1f4eb5d",
  "result": {
    "markdown": "# Appendix {.unnumbered}\n\nThis is an appendix of all code used in this project. Click the code buttons under each header to display the code chunk. You may also return to each chapter and view each individual code chunk by clicking the code buttons.\n\n# Chapter 3: Examples\n\n## Libraries\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load Libraries for Chapter 3\nlibrary(factoextra) #fviz_eig; PCA plots\nlibrary(tidyverse)  #rename; pipe operator\nlibrary(kableExtra) #kable_paper; table formatting\nlibrary(corrplot) #for plotting the correlation matrix\nlibrary(summarytools) #produces summary stats\n```\n:::\n\n\nThe packages used in this chapter are tidyverse @tidyverse, kableExtra @kableExtra,  factoextra @factoextra, corrplot @corrplot2021 and summarytools @summarytools.\n\n## Code\n\n::: {.cell}\n\n```{.r .cell-code}\n# Import Example Data\ndata = data.frame(Student = 1:4, BasicStats=c(4,8,13,7), AdvancedStats=c(11,4,5,14))\n#dim(data)\n\n# Structure of Data\n# check variable types which matters in PCA \n# summary(data) #details about variable scales and missing values\nkbl(data, align = 'l', caption = \"Dataframe structure\") %>%\n  kable_paper(\"hover\")\n\n# Based on Info from Summary: handle missing values and exclude categorical variable\n# na.omit(data) No missing values here\ndata_sample = data[,-c(1)] #exclude categorical variable\n\n# Run PCA\ndata_pca = prcomp(data_sample, scale = TRUE)\n\n# Summary of Analysis\nsum_pca = as.data.frame(summary(data_pca)$importance)\nkbl(sum_pca, align= 'l', caption = \"Importance of components\") %>%\n  kable_paper(\"hover\")\n\n# Elements of PCA Object (all outputs of PCA analysis)\n# names(data_pca)\n\n# sdev:standard deviation\n# rotation: eigenvectors (loadings per variable within each PC)\n# center: mean of the original variable\n# scale: standard deviations of the original variable\n# x: principal component values/scores\n\n# Scree Plot of Variance\nfviz_eig(data_pca,\n         addlabels = TRUE)\n# Biplot with Default Settings\nfviz_pca_biplot(data_pca, repel = TRUE)\n\n# Load dataset\nabalone <- read.csv('./abalone/abalone.csv')\n\ndata_desc = descr(abalone, plain.ascii = FALSE, headings = FALSE) # descriptive statistics for the dataset\n\ndata_desc %>%\n  kbl(align= 'l') %>%\n  kable_paper(\"hover\")\n\n# Select only the numeric variables \nabalone = select_if(abalone, is.numeric)\n\n# Standardization of numerical features\nabalone_sc <- scale(abalone, center = TRUE, scale = TRUE)\n\nsc_sum = summary(abalone_sc)\n\nkbl(sc_sum, align= 'l') %>%\n  kable_paper(\"hover\")\n\n# Plot a boxplot to visualize potential outliers\npar(mar=c(4, 8, 4, 4))\nboxplot(abalone_sc, col = \"steelblue\", main = \"Visualization of scaled and centered data\", horizontal = TRUE, las = 1)\n\nouts = colSums(abalone_sc > 3 | abalone_sc < -3)\n\nkbl(outs, col.names = ('Outliers'), align = 'l') %>%\n  kable_paper(\"hover\")\n\n# Calculate correlations and round to 2 digits\nabalone_corr <- cor(abalone_sc)\ncorrplot(abalone_corr, method=\"number\")\n\n# Apply PCA using prcomp()\nabalone_pca <- prcomp(abalone_sc)\n\nsum_pca = as.data.frame(summary(abalone_pca)$importance)\n\nkbl(sum_pca, align= 'l', caption = \"Importance of components\") %>%\n  kable_paper(\"hover\")\n\n# Principal Component scores vector\npc_scores <- abalone_pca$x\n\n# Std Deviation of Components\ncomponent_sdev <- abalone_pca$sdev\n\n# Eigenvector or Loadings\neigenvector <- abalone_pca$rotation\n\n# Mean of variables\ncomponent_mean <- abalone_pca$center \n\n# Scaling factor of Variables\ncomponent_scale <- abalone_pca$scale\n\n# Proportion of variance explained by each PC\nvariance_explained <- component_sdev^2 / sum(component_sdev^2)\n\n# Cumulative proportion of variance explained\ncumulative_variance_explained <- cumsum(variance_explained)\n\n# Retain components that explain a percentage of the variance\nnum_components <- which(cumulative_variance_explained >= 0.92)[1]\n\n# Select the desired number of principal components\nselected_pcs <- pc_scores[, 1:num_components]\n\n# Access the loadings for the first two principal components\nloadings_first_two_components <- eigenvector[, 1:2]\n\n# Print the loadings for the first two principal components\n\nkbl(loadings_first_two_components, align= 'l', caption = \"Loadings for the first two principal components\") %>%\n  kable_paper(\"hover\")\n\nfviz_eig(abalone_pca, addlabels = TRUE)\n\nfviz_pca_biplot(abalone_pca, label = \"var\", alpha.ind = \"contrib\", col.var = \"blue\", repel = TRUE)\n\n# Contributions of variables to PC1\npc2_contribution <- fviz_contrib(abalone_pca, choice = \"var\", axes = 1, top = 20)\n\n# Modify the theme to rotate X-axis labels to 90 degrees\npc2_contribution +\n  theme(\n    axis.text.x = element_text(angle = 0),\n    plot.title = element_text(hjust = 0)  # horizontal justification\n  ) +\n  coord_flip() +\n  labs(title = \"Contribution of Variables to PC1\",\n       y = \"Percentage Contribution\",\n       x = \"\",\n       caption = \"PC1 explains 83.9% of the variance\") +\n  scale_y_continuous(labels = scales::percent_format(scale = 1,\n                                                     accuracy = 1))\n\n# Contributions of variables to PC2\npc2_contribution <- fviz_contrib(abalone_pca, choice = \"var\", axes = 2, top = 12)\n\n# Modify the theme to rotate X-axis labels to 90 degrees\npc2_contribution +\n  theme(\n    axis.text.x = element_text(angle = 0),\n    plot.title = element_text(hjust = 0)  # horizontal justification\n  ) +\n  coord_flip() +\n  labs(title = \"Contribution of Variables to PC2\",\n       y = \"Percentage Contribution\",\n       x = \"\",\n       caption = \"PC2 explains 8.7% of the variance\") +\n  scale_y_continuous(labels = scales::percent_format(scale = 1,\n                                                     accuracy = 1))\n```\n:::\n\n\n# Chapter 4: Dataset\n\n## Libraries\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load libraries\nlibrary(tidyverse)\nlibrary(summarytools)\nlibrary(kableExtra)\nlibrary(DataExplorer)\n```\n:::\n\n\nThe packages used for this chapter are tidyverse @tidyverse, summarytools @summarytools, kableExtra @kableExtra, and DataExplorer @DataExplorer.\n\n## Code\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the dataset\ndata <- read.csv('./dataset/DFC_STATE.csv')\n\n# Make a working copy\ntrain_data <- data\n\n# Constant seed\nmy_seed = 95\n\n# Rename the variables\ntrain_data <- rename(train_data,\n        better_transfusion = Transfusions..Better.than.expected..STATE.,\n        expected_transfusion = Transfusions..As.expected..STATE.,\n        worse_transfusion = Transfusions..Worse.than.expected..STATE.,\n        better_infection = Infection..Better.than.expected..STATE.,\n        expected_infection = Infection..As.expected..STATE.,\n        worse_infection = Infection..Worse.than.expected..STATE.,\n        Kt_v_1.2 = Percentage.of.adult.HD.patients.with.Kt.V..1.2,\n        Kt_v_1.7 = Percentage.Of.Adult.PD.Patients.With.Kt.V..1.7,\n        pedriatic_Kt_v_1.2 = Percentage.Of.Pediatric.HD.Patients.With.Kt.V..1.2,\n        pediatric_Kt_v_1.8 = Percentage.Of.Pediatric.PD.Patients.With.Kt.V..1.8,\n        pediatric_nPCR = Percentage.Of.Pediatric.HD.Patients.With.nPCR.In.Use,\n        better_fistula = Fistula.Rate...Better.Than.Expected..STATE.,\n        expected_fistula = Fistula.Rate...As.Expected..STATE.,\n        worse_fistula = Fistula.Rate...Worse.Than.Expected..STATE.,\n        long_term_catheter = Percentage.Of.Adult.Patients.With.Long.Term.Catheter.In.Use ,\n        \"hypercalcemia_calcium > 10.2Mg\" = Percentage.Of.Adult.Patients.With.Hypercalcemia..Serum.Calcium.Greater.Than.10.2.Mg.dL.,\n        \"phosphorus < 3.5Mg\" = Percentage.Of.Adult.Patients.With.Serum.Phosphorus.Less.Than.3.5.Mg.dL,\n        \"phosphorus (3.5 - 4.5) Mg\" = Percentage.Of.Adult.Patients.With.Serum.Phosphorus.Between.3.5.4.5.Mg.dL,\n        \"phosphorus (4.6 - 5.5) Mg\" = Percentage.Of.Adult.Patients.With.Serum.Phosphorus.Between.4.6.5.5.Mg.dL,\n        \"phosphorus (5.6 - 7) Mg\" = Percentage.Of.Adult.Patients.With.Serum.Phosphorus.Between.5.6.7.0.Mg.dL,\n        \"phosphorus > 7Mg\" = Percentage.Of.Adult.Patients.With.Serum.Phosphorus.Greater.Than.7.0.Mg.dL,\n        better_hospitalization = Hospitalizations..Better.Than.Expected..STATE.,\n        expected_hospitalization = Hospitalizations..As.Expected..STATE.,\n        worse_hospitalization = Hospitalizations..Worse.Than.Expected..STATE.,\n        better_hospital_readmission = Hospital.Readmission...Better.Than.Expected..STATE.,\n        expected_hospital_readmission = Hospital.Readmission...As.Expected..STATE.,\n        worse_hospital_readmission = Hospital..Readmission...Worse.Than.Expected..STATE.,\n        better_survival = Survival..Better.Than.Expected..STATE.,\n        expected_survival = Survival..As.Expected..STATE.,\n        worse_survival = Survival..Worse.Than.Expected..STATE.,\n        incident_transplant_waitlist_better = Incident.Patients.Transplant.Waitlisting..Better.Than.Expected..STATE.,\n        incident_transplant_waitlist_expected = Incident.Patients.Transplant.Waitlisting...As.Expected..STATE.,\n        incident_transplant_waitlist_worse = Incident.Patients.Transplant.Waitlisting...Worse.Than.Expected..STATE.,\n        prevalent_transplant_waitlist_better = Prevalent.Patients.Transplant.Waitlisting..Better.Than.Expected..STATE.,\n        prevalent_transplant_waitlist_expected = Prevalent.Patients.Transplant.Waitlisting...As.Expected..STATE.,\n        prevalent_transplant_waitlist_worse = Prevalent.Patients.Transplant.Waitlisting...Worse.Than.Expected..STATE.,\n        Hgb_10g = Percentage.Of.Patients.With.Hgb.10.g.dL,\n        Hgb_12g = Percentage.of.patients.with.Hgb.12.g.dL\n        )\n\ndata_desc = descr(train_data, plain.ascii = FALSE, headings = FALSE) # descriptive statistics for the dataset\n\nkbl(data_desc, align= 'l') %>%\n  kable_paper(\"hover\")\n\n# Plot Missing values\nplot_intro(train_data)\nplot_missing(train_data, missing_only = TRUE, group = list(\"Good (0.05)\" = 0.05, \"OK (0.4)\" = 0.4, Bad = 0.8, Remove = 1),)\n\ntotal_missing <- sum(is.na(train_data))\n# cat(\"Count Missing Values in Entire Data Frame: \", total_missing)\n\n# Count the number of missing values in each column\nno_missing_values_df <- data.frame(\"Missing_Values\" = colSums(is.na(train_data)))\n\n# Table format\nkbl(no_missing_values_df) %>%\n  kable_paper(\"hover\", full_width = F)\n\n# Visualize of data in histograms\nplot_histogram(train_data[, 18:25], ncol = 2L)\n\n# Plot qq\nplot_qq(train_data[, 19:30], ncol = 2L)\n\n# Remove categorical columns\ntrain_data$State <- NULL\n\n# Impute missing values with the median\nfor (col in colnames(train_data)) {\n  median_value <- median(train_data[[col]], na.rm = TRUE)\n  train_data[[col]] <- ifelse(is.na(train_data[[col]]), median_value, train_data[[col]])\n}\n\n# Round all variables\ntrain_data <- round(train_data, digits = 0)\n\n# Count the number of missing values in each column\nno_missing_values_df <- data.frame(\"Missing_Values\" = colSums(is.na(train_data)))\n\nType = sapply(train_data, typeof)\nno_missing_values_df <- cbind(no_missing_values_df, Type)\n\n# table format\nkbl(no_missing_values_df) %>%\n  kable_paper(\"hover\", full_width = F)\n```\n:::\n\n\n# Chapter 5: Analysis\n\n## Libraries\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load libraries\nlibrary(tidyverse)  #rename; pipe operator\nlibrary(olsrr)      #ols_plot_resid_lev; outliers, leverage plot\nlibrary(caret)      #findCorrelation\nlibrary(kableExtra) #kable_paper; table formatting\nlibrary(sjPlot)     #tab_model; format linear regression results\nlibrary(factoextra) #fviz_eig; PCA plots\nlibrary(caTools)    #sample.split\nlibrary(ggcorrplot) #ggcorrplot; correlation graph\nlibrary(pls)        #pcr; PC regression\nlibrary(Metrics)    #mae; calculate MAE, MSE, RMSE, R^2\n```\n:::\n\n\nThe packages used in this analysis are tidyverse @tidyverse, olsrr @olsrr, caret @caret, kableExtra @kableExtra, sjPlot @sjPlot, factoextra @factoextra, caTools @caTools, ggcorrplot @ggcorrplot, pls @pls, and Metrics @Metrics.\n\n## Code\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load dataset\ntrain_original <- read.csv('dataset/DFC_STATE.csv')\n\n# Make a working copy\ntrain_data <- train_original\n\n# Constant seed\nmy_seed = 95\n\n# Rename Variables\ntrain_data <- rename(train_data,\n                      better_transfusion = Transfusions..Better.than.expected..STATE.,\n        expected_transfusion = Transfusions..As.expected..STATE.,\n        worse_transfusion = Transfusions..Worse.than.expected..STATE.,\n        better_infection = Infection..Better.than.expected..STATE.,\n        expected_infection = Infection..As.expected..STATE.,\n        worse_infection = Infection..Worse.than.expected..STATE.,\n        Kt_v_1.2 = Percentage.of.adult.HD.patients.with.Kt.V..1.2,\n        Kt_v_1.7 = Percentage.Of.Adult.PD.Patients.With.Kt.V..1.7,\n        pedriatic_Kt_v_1.2 = Percentage.Of.Pediatric.HD.Patients.With.Kt.V..1.2,\n        pediatric_Kt_v_1.8 = Percentage.Of.Pediatric.PD.Patients.With.Kt.V..1.8,\n        pediatric_nPCR = Percentage.Of.Pediatric.HD.Patients.With.nPCR.In.Use,\n        better_fistula = Fistula.Rate...Better.Than.Expected..STATE.,\n        expected_fistula = Fistula.Rate...As.Expected..STATE.,\n        worse_fistula = Fistula.Rate...Worse.Than.Expected..STATE.,\n        long_term_catheter = Percentage.Of.Adult.Patients.With.Long.Term.Catheter.In.Use ,\n        \"hypercalcemia_calcium > 10.2Mg\" = Percentage.Of.Adult.Patients.With.Hypercalcemia..Serum.Calcium.Greater.Than.10.2.Mg.dL.,\n        \"phosphorus < 3.5Mg\" = Percentage.Of.Adult.Patients.With.Serum.Phosphorus.Less.Than.3.5.Mg.dL,\n        \"phosphorus (3.5 - 4.5) Mg\" = Percentage.Of.Adult.Patients.With.Serum.Phosphorus.Between.3.5.4.5.Mg.dL,\n        \"phosphorus (4.6 - 5.5) Mg\" = Percentage.Of.Adult.Patients.With.Serum.Phosphorus.Between.4.6.5.5.Mg.dL,\n        \"phosphorus (5.6 - 7) Mg\" = Percentage.Of.Adult.Patients.With.Serum.Phosphorus.Between.5.6.7.0.Mg.dL,\n        \"phosphorus > 7Mg\" = Percentage.Of.Adult.Patients.With.Serum.Phosphorus.Greater.Than.7.0.Mg.dL,\n        better_hospitalization = Hospitalizations..Better.Than.Expected..STATE.,\n        expected_hospitalization = Hospitalizations..As.Expected..STATE.,\n        worse_hospitalization = Hospitalizations..Worse.Than.Expected..STATE.,\n        better_hospital_readmission = Hospital.Readmission...Better.Than.Expected..STATE.,\n        expected_hospital_readmission = Hospital.Readmission...As.Expected..STATE.,\n        worse_hospital_readmission = Hospital..Readmission...Worse.Than.Expected..STATE.,\n        better_survival = Survival..Better.Than.Expected..STATE.,\n        expected_survival = Survival..As.Expected..STATE.,\n        worse_survival = Survival..Worse.Than.Expected..STATE.,\n        incident_transplant_waitlist_better = Incident.Patients.Transplant.Waitlisting..Better.Than.Expected..STATE.,\n        incident_transplant_waitlist_expected = Incident.Patients.Transplant.Waitlisting...As.Expected..STATE.,\n        incident_transplant_waitlist_worse = Incident.Patients.Transplant.Waitlisting...Worse.Than.Expected..STATE.,\n        prevalent_transplant_waitlist_better = Prevalent.Patients.Transplant.Waitlisting..Better.Than.Expected..STATE.,\n        prevalent_transplant_waitlist_expected = Prevalent.Patients.Transplant.Waitlisting...As.Expected..STATE.,\n        prevalent_transplant_waitlist_worse = Prevalent.Patients.Transplant.Waitlisting...Worse.Than.Expected..STATE.,\n        \"Hgb 10g\"= Percentage.Of.Patients.With.Hgb.10.g.dL,\n        \"Hgb 12g\" = Percentage.of.patients.with.Hgb.12.g.dL\n        )\n\n# Impute Missing Values\n# Count the number of missing values in each column\ncolSums(is.na(train_data))\n\n# Remove categorical columns\ntrain_data$State <- NULL\n\n# Impute missing values with the mean\nfor (col in colnames(train_data)) {\n  mean_value <- mean(train_data[[col]], na.rm = TRUE)\n  train_data[[col]] <- ifelse(is.na(train_data[[col]]), mean_value,     train_data[[col]])\n}\n\n# Remove rows with missing values\ntrain_data <- na.omit(train_data)\n\n# Count the number of missing values in each column\ncolSums(is.na(train_data))\n\n# Get duplicated rows\ntrain_data[duplicated(train_data), ]\n\n# Summary statistics of the data\nsummary(train_data)\n\n# Summary statistics of categorical variables\nsummary(train_data[, sapply(train_data, is.character)])\n\n# Check dataset structure\nstr(train_data)\n\n# Find the index position of the target feature \ntarget_name <- \"expected_survival\"\ntarget_index <- grep(target_name, \n                     colnames(train_data))\n\n# Standardization Numerical Features\ntrain_data_sc <- scale(train_data[, -target_index])\n\n# Plot a boxplot to visualize potential outliers\nboxplot(train_data, main = \"Outliers Detection\",\n        col = \"steelblue\")\n\n# Dependent Variable outliers\ntrain_data %>% \n  ggplot(aes(y=expected_survival)) +\n  geom_boxplot(fill=\"steelblue\", alpha=0.75) + \n  xlab(\"Expected Survival\")+\n  ylab(\"\")+\n  ggtitle(\"Dependent Variable Outliers\")\n\nset.seed(my_seed)\n\n# Fit regression model\nordinary_model <- lm(expected_survival ~ ., data = train_data)\n\n# Print the model summary\nsummary(ordinary_model)\n\n# Residual Diagnostics\nols_plot_resid_lev(ordinary_model)\n\n# No Outliers subset\nno_outliers_df <- slice(train_data, -c(56))\n\nset.seed(my_seed)\n\n# Fit regression model\nno_outliers_model <- lm(expected_survival ~ ., data = no_outliers_df)\n\n# Print the model summary\nsummary(no_outliers_model)\n\n# Residual Diagnostics\nols_plot_resid_lev(no_outliers_model)\n\n# Calculate correlations and round to 2 digits\ncorr_matrix <- cor(train_data_sc)\ncorr_matrix <- round(corr_matrix, digits = 2)\n\n# Print names of highly correlated features; threshold > 0.30\nhigh <- findCorrelation(corr_matrix, cutoff = 0.30, names = TRUE)\n\n# Create a data frame with an index column\nhigh_corr_df <- data.frame(\n  Count = 1:length(high),\n  Feature = high\n)\n\n# table format\nkbl(high_corr_df, caption = \"Highly Correlated Features\") %>%\n  kable_paper(\"hover\")\n\ncorrplot::corrplot(corr_matrix, type = \"full\", tl.pos = \"n\")\n\nset.seed(my_seed)\n\n# Fit a multiple linear regression model\nfull_model <- lm(expected_survival ~ ., data = train_data)\n\n# Print a summary of the regression model\ntab_model(full_model, title = \"Full Model Regression\", \n          string.p=\"P-value\", string.stat = \"T-score\",\n          string.se = \"Std. Error\",\n          string.resp = \"Response\",\n          string.ci = \"Conf Int.\",\n          show.se=T, show.stat = T,\n           CSS = list(\n             css.depvarhead = 'font-weight: bold; text-align: left;',\n             css.summary = 'color: #10759B; font-weight: bold;'\n           ))\n\n# Apply PCA using prcomp()\ndata_pca <- prcomp(train_data_sc, center = TRUE, scale. = TRUE)\npca_summ <- summary(data_pca)$importance\n\n# Transpose the matrix\ntransposed_pca_summ <- t(pca_summ)\n\n# table format\nkbl(transposed_pca_summ, caption = \"Pricipal Components Analysis\",\n    digits = 4) %>%\n  kable_paper(\"hover\")\n\n# Principal Component scores vector\npc_scores <- data_pca$x\n\n# Std Deviation of Components\ncomponent_sdev <- data_pca$sdev\n\n# Eigenvector, or Loadings\npc_loadings <- data_pca$rotation\n\n# Mean of variables\ncomponent_mean <- data_pca$center \n\n# Scaling factor of Variables\ncomponent_scale <- data_pca$scale\n\n# Access the loadings for the first two principal components\nloadings_first_two_components <- pc_loadings[, 1:2]\n\n# Print the loadings for the first two principal components\n# print(loadings_first_two_components)\n\n# table format\nkbl(loadings_first_two_components, \n    caption = \"Loadings of First Two Principal Components\",\n    digits = 4) %>%\n  kable_paper(\"hover\")\n\n# Proportion of variance explained by each PC\nvariance_explained <- component_sdev^2 / sum(component_sdev^2)\n\n# Cumulative proportion of variance explained\ncumulative_variance_explained <- cumsum(variance_explained)\n\n# Create a data frame with an index column\ncumulative_variance_explained_df <- data.frame(\n  Pincipal_Component = 1:length(cumulative_variance_explained),\n  Cumulative_Variance_Explained = cumulative_variance_explained\n)\n\n# Create a kable table with an index column\nkbl(cumulative_variance_explained_df, align = \"cl\",\n    caption = \"PCA: Cumulative Variance Explained\",\n    digits = 4) %>%\n  kable_paper(\"hover\")\n\n# Retain components that explain a percentage of the variance\nnum_components <- which(cumulative_variance_explained >= 0.86)[1]\n\n# Select the desired number of principal components\nselected_pcs <- pc_scores[, 1:num_components]\n\n# table format\nkbl(selected_pcs, caption = \"Components Explaining 86% Variance\",\n    digits = 4) %>%\n  kable_paper(\"hover\", full_width = F)\n\nfviz_eig(data_pca, addlabels = TRUE)\n\nfviz_pca_biplot(data_pca, \n                geom = c(\"point\", \"arrow\"),\n                geom.var = \"arrow\")\n\n# Control variable colors using their contributions\nfviz_pca_var(data_pca, col.var = \"contrib\",\n   gradient.cols = c(\"white\", \"blue\", \"red\"),\n   geom.var = \"arrow\",\n   ggtheme = theme_minimal())\n\n# Contributions of variables to PC1\npc2_contribution <- fviz_contrib(data_pca, choice = \"var\", axes = 1, top = 20)\n\n# Modify the theme to rotate X-axis labels to 90 degrees\npc2_contribution +\n  theme(\n    axis.text.x = element_text(angle = 0),\n    plot.title = element_text(hjust = 0)  # horizontal justification\n  ) +\n  coord_flip() +\n  labs(title = \"Contribution of Variables to PC1\",\n       y = \"Percentage Contribution\",\n       x = \"\",\n       caption = \"PC1 explains 40.8% variance\") +\n  scale_y_continuous(labels = scales::percent_format(scale = 1,\n                                                     accuracy = 1))\n\n\n# Contributions of variables to PC2\npc2_contribution <- fviz_contrib(data_pca, choice = \"var\", axes = 2, top = 12)\n\n# Modify the theme to rotate X-axis labels to 90 degrees\npc2_contribution +\n  theme(\n    axis.text.x = element_text(angle = 0),\n    plot.title = element_text(hjust = 0)  # horizontal justification\n  ) +\n  coord_flip() +\n  labs(title = \"Contribution of Variables to PC2\",\n       y = \"Percentage Contribution\",\n       x = \"\",\n       caption = \"PC2 explains 9.5% variance\") +\n  scale_y_continuous(labels = scales::percent_format(scale = 1,\n                                                     accuracy = 1))\n\n# reproducible random sampling\nset.seed(my_seed)  \n \n# Create Target y-variable for the training set\ny <- train_data$expected_survival  \n# Split the data into training and test sets \nsplit <- sample.split(y, SplitRatio = 0.7) \ntraining_set <- subset(train_data, split == TRUE) \ntest_set <- subset(train_data, split == FALSE) \n\n# Feature Scaling: Standardization\n# Perform centering and scaling on the training and test sets\nsc <- preProcess(training_set[, -target_index], \n                 method = c(\"center\", \"scale\"))\ntraining_set[, -target_index] <- predict(\n  sc, training_set[, -target_index])\ntest_set[, -target_index] <- predict(sc, test_set[, -target_index])\n\n# Perform Principal Component Analysis (PCA) preprocessing on the training data\npca <- preProcess(training_set[, -target_index], \n                  method = 'pca', pcaComp = 8)\n\n# Apply PCA transformation to original training set\ntraining_set <- predict(pca, training_set)\n\n# Reorder columns, moving the dependent feature index to the end\ntraining_set <- training_set[c(2:9, 1)]\n\n# Apply PCA transformation to original test set\ntest_set <- predict(pca, test_set)\n\n# Reorder columns, moving the dependent feature index to the end\ntest_set <- test_set[c(2:9, 1)]\n\n#PRESS & Predicted $R^2$ Functions\n#PRESS - predicted residual sums of squares\nPRESS <- function(linear.model) {\n  # calculate the predictive residuals\n  pr <- residuals(linear.model)/(1-lm.influence(linear.model)$hat)\n  # calculate the PRESS\n  PRESS <- sum(pr^2)\n  \n  return(PRESS)\n}\n\npred_r_squared <- function(linear.model) {\n  # Use anova() to get the sum of squares for the linear model\n  lm.anova <- anova(linear.model)\n  # Calculate the total sum of squares\n  tss <- sum(lm.anova$'Sum Sq')\n  # Calculate the predictive R^2\n  pred.r.squared <- 1-PRESS(linear.model)/(tss)\n  \n  return(pred.r.squared)\n}\n\n# reproducible random sampling\nset.seed(my_seed)\n\n# Fit a multiple linear regression model\npca_full_model <- lm(expected_survival ~ ., data = training_set)\n\n# Print a summary of the regression model\ntab_model(pca_full_model, title = \"8 Principal Components Regression\",\n          string.p=\"P-value\", string.stat = \"T-score\",\n          string.se = \"Std. Error\",\n          string.resp = \"Response\",\n          string.ci = \"Conf Int.\",\n          show.se=T, show.stat = T,\n          CSS = list(\n             css.depvarhead = 'font-weight: bold; text-align: left;',\n             css.summary = 'color: #10759B; font-weight: bold;'\n           ))\n\n# Calculate PRESS\n# cat(\"PRESS: \", PRESS(pca_full_model), \"\\n\")\nPRESS_8pc <- PRESS(pca_full_model)\n# Calculate predicted R^2\n# cat(\"Predicted R^2: \", pred_r_squared(pca_full_model), \"\\n\")\nR2_8pcs <- pred_r_squared(pca_full_model)\n\npredict_8pc <- cbind(PRESS_8pc, R2_8pcs)\n# Print PRESS, predicted R^2\n# table format\nkbl(predict_8pc, caption = \"8 Principal Components Prediction Metrics\",\n    digits = 4) %>%\n  kable_paper(\"hover\", full_width = F)\n\n# Visual of Principal Components un-correlation\ncorr_matrix <- cor(training_set)\nggcorrplot(corr_matrix)\n\n# Create a subset with 2 principal components\nsignificant_pcs = c(1,2,9)\ntrain_pca <- training_set[, significant_pcs]\ntest_pca <- test_set[, significant_pcs]\n\n# reproducible random sampling\nset.seed(my_seed)\n\n# Fit a multiple linear regression model\nreg_model <- lm(expected_survival ~ ., \n                data = train_pca)\n\n# Print a summary of the regression model\ntab_model(reg_model, title = \"2 Principal Components Regression\",\n          string.p=\"P-value\", string.stat = \"T-score\",\n          string.se = \"Std. Error\",\n          string.resp = \"Response\",\n          string.ci = \"Conf Int.\",\n          show.se=T, show.stat = T,\n          CSS = list(\n             css.depvarhead = 'font-weight: bold; text-align: left;',\n             css.summary = 'color: #10759B; font-weight: bold;'\n           ))\n\n# Calculate PRESS\n# cat(\"PRESS: \", PRESS(reg_model), \"\\n\")\nPRESS_2pc <- PRESS(reg_model)\n\n# Calculate predicted R^2\n# cat(\"Predicted R^2: \", pred_r_squared(reg_model), \"\\n\")\nR2_2pc <- pred_r_squared(reg_model)\n\n# Print 2PC prediction results\npredict_2pc <- cbind(PRESS_2pc, R2_2pc)\n\n# table format\nkbl(predict_2pc, caption = \"2 Principal Components Prediction Metrics\",\n    digits = 4) %>%\n  kable_paper(\"hover\", full_width = F)\n\n# reproducible random sampling\nset.seed(my_seed)\n\ny = train_pca$expected_survival\n\n# fit PCR\npcr_model <- pcr(y ~ PC1+PC2, data=train_pca, validation=\"CV\")\nprint(pcr_model)\n\n# table format\n# kbl(pcr_model$residuals, caption = \"PCA Residuals\",\n#     digits = 4) %>%\n#   kable_paper(\"hover\", full_width = F)\n\n# reproducible random sampling\nset.seed(my_seed)\n\n# Cross-validation with n folds\nk_10 <- trainControl(method = \"cv\", number = 10)\n\n# training the model \nmodel_cv <- train(expected_survival ~ ., \n                  data = train_pca,\n                  method = \"lm\",\n                  trControl = k_10)\n\n# Print Model Performance\nprint(model_cv)\n\n# Metrics\ncv_results = model_cv$results\nkbl(cv_results, caption = \"PCA: Cross-Validation Metrics\",\n    digits = 4) %>%\n  kable_paper(\"hover\", full_width = F)\n\n# Find the index position of the target feature\npred_target_index <- grep(target_name, \n                     colnames(test_pca))\n#cat(\"Target Feature Index =\", pred_target_index)\n\n# Create Predicted Target Feature (y-test) \ny_test <- test_pca[pred_target_index]\n\n# Predictions using the Cross-Validation model\ny_pred = predict(model_cv, newdata = test_pca[, -pred_target_index])\n\n# Prediction Results from y_predictions\ny_pred <- round(y_pred, digits = 0)\n\n# Transform y_test from data frame to numeric\ny_test <- as.numeric(unlist(y_test))\n\nprediction_comparison <- cbind(y_pred, y_test)\n# table format\nkbl(prediction_comparison) %>%\n  kable_paper(\"hover\", full_width = F)\n\n# Calculate Mean Absolute Error (MAE)\nMAE_value <- mae(y_pred, y_test)\n#cat(\"MAE =\", mae_value)\n\n# Calculate MSE\nMSE_predict <- mean((y_pred - y_test)^2)\n#cat(\"\\nMSE =\", mse_predict)\n\n# Calculate RMSE\nRMSE_predict <- sqrt(mean((y_pred - y_test)^2))\n#cat(\"\\nRMSE =\", rmse_predict)\n\n# Calculate R-squared (R^2)\npredicted_R2 <- 1 - sum((y_test - y_pred)^2) / \n  sum((y_test - mean(y_test))^2)\n# cat(\"\\nPredicted R^2 =\", predicted_r2)\n\nprediction_metrics_df <- cbind(MAE_value, MSE_predict,\n                               RMSE_predict, predicted_R2)\n# table format\nkbl(prediction_metrics_df, digits = 4) %>%\n  kable_paper(\"hover\", full_width = F)\n```\n:::",
    "supporting": [
      "appendix_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}