{
  "hash": "3c258c4ddec54e2dd44068225e9e77e3",
  "result": {
    "markdown": "# Examples\n\nMoving beyond the theoretical foundations of principal components, how is PCA applied to data? We offer two examples; the first a demonstration of the manual calculation of principal components, and the second implementing PCA on a large dataset using R.\n\n## Manual calculation of principal components\n\nIn this illustration, we have access to the two grades of four students in a statistics subject. We aim to employ principal component analysis as a means to reduce the dimensionality from two variables to a singular variable. This transformation will effectively represent students' performance in the subject with a more compact and interpretable measure. This example is adapted from the resource *How to compute principal components* @eduflair2020.\n\n| Scores        | **Basic Stats**   | **Advanced Stats**  |\n|---------------|-------------------|---------------------|\n| **Student 1** | **4**             | **11**              |\n| **Student 2** | **8**             | **4**               |\n| **Student 3** | **13**            | **5**               |\n| **Student 4** | **7**             | **14**              |\n| **Mean**      | $\\bar{x}$ = **8** | $\\bar{y}$ = **8.5** |\n\n### Calculate the covariance matrix $M$\n\n$$\n\\begin{bmatrix}\n\\text{cov}(x,x) & \\text{cov}(x,y) \\\\\n\\text{cov}(y,x) & \\text{cov}(y,y) \\\\\n\\end{bmatrix}\n$$\n\n$\\Rightarrow$ $\\text{cov}(x,x)$ = $\\text{var}(x)$ = $\\mathbf{E}$($x^2$) - $\\mathbf{E}$ $(x)^2$ = $$ \\frac{(16+0+25+1)}{3}=14 $$\n\n$\\Rightarrow$ $\\text{cov}(y,y)$ = $\\text{var}(y)$ = $\\mathbf{E}$($y^2$) - $\\mathbf{E}$ $(y)^2$ = $$ \\frac{(6.25+20.25+12.25+30.25)}{3}=23 $$\n\n$\\Rightarrow$ $\\text{cov}(x,y)$ = $\\text{cov}(y,x)$ = $\\mathbf{E}$($xy$) - $\\mathbf{E}$ ($x$)$\\mathbf{E}$ ($y$) = $$ \\frac{(-10+0-17.5-5.5)}{3}=-11 $$\n\n$\\Rightarrow$ Covariance Matrix $M$ $$ \n\\begin{bmatrix}\n14 & -11 \\\\\n-11 & 23 \\\\\n\\end{bmatrix} $$\n\n### Compute the singular value decomposition (SVD)\n\nWe can obtain the principal components and loadings from SVD of the covariance matrix M since covariance matrix M is a square matrix:\n\n$$ \n\\begin{bmatrix}\n14 & -11 \\\\\n-11 & 23 \\\\\n\\end{bmatrix} \\times Any\\ vector = \\lambda \\times Any\\ vector\\ ,\\ (vector\\neq 0) \n$$\n\n$$det(M - \\lambda I) = 0$$\n\n#### Obtain eigenvalues of the covariance matrix $\\rightarrow$ $\\lambda_1$ & $\\lambda_2$\n\n$$\nI = \\begin{bmatrix}\n1 & 0 \\\\\n0 & 1 \\\\\n\\end{bmatrix}\n$$\n\n$$\n\\lambda I = \\lambda \\times \\begin{bmatrix}\n1 & 0 \\\\\n0 & 1 \\\\\n\\end{bmatrix} = \\begin{bmatrix} \n\\lambda  & 0 \\\\\n0 & \\lambda  \\\\\n\\end{bmatrix}\n$$\n\n$$\n\\begin{bmatrix}\n14 & -11 \\\\\n-11&  23 \\\\\n\\end{bmatrix} -\\begin{bmatrix}\n\\lambda  & 0 \\\\\n0 & \\lambda  \\\\\n\\end{bmatrix} = \\begin{bmatrix}\n14-\\lambda  & -11 \\\\\n-11 & 23-\\lambda  \\\\\n\\end{bmatrix}\n$$\n\n$\\Rightarrow$\n\n$$\ndet\\begin{bmatrix}\n 14-\\lambda & -11 \\\\\n -11& 23-\\lambda  \\\\\n\\end{bmatrix}=0\n$$\n\n$\\Rightarrow$ $$(14-\\lambda)(23-\\lambda) - (-11)(-11) = 0 $$\n\n$$\\lambda^2 +37\\lambda -201 = 0$$\n\n$\\Rightarrow$ $\\lambda_1$ = 30.3849, $\\lambda_2$ = 6.6152 (eigenvalues for Covariance Matrix $M$)\n\n#### Obtain eigenvector of $\\lambda_1$\n\n$$(M - \\lambda_1I)\\times U_1 = \\mathbf{0} $$\n\n$\\Rightarrow$ $$\\begin{bmatrix}\n 14-\\lambda & -11 \\\\\n -11& 23-\\lambda  \\\\\n\\end{bmatrix}\\times\\begin{bmatrix}\nu_1 \\\\\nu_2 \\\\\n\\end{bmatrix}=\\mathbf{0}\n$$\n\n$$(14- \\lambda)u_1 - 11u_2 = 0 $$ $\\Rightarrow$ $$-16.3849u_1 -11u_2 = 0$$ $\\Rightarrow$ $$-16.3849u_1= 11u_2 $$ $\\Rightarrow$ $$u_1 = \\frac{11}{-16.3849}u_2$$\n\n$$\n\\begin{bmatrix}\nu_1 \\\\\nu_2 \\\\\n\\end{bmatrix}= u_2\\begin{bmatrix}\n\\frac{11}{-16.3849}\\\\\n1 \\\\\n\\end{bmatrix}\n$$\n\n$\\Rightarrow$ $$u_2\\begin{bmatrix}\n-11\\\\ 16.3849\n\\end{bmatrix}$$\n\n$$\n\\begin{bmatrix}\n16.3849 & 11 \\\\\n\\end{bmatrix} \\times \\begin{bmatrix}\nu_1 \\\\ u_2\n\\end{bmatrix} = \\begin{bmatrix}\n11 \\\\ -16.3849\n\\end{bmatrix}\n$$\n\n**Normalized Eigenvector**\n\n$\\Rightarrow$ $\\lambda_1$: $e_1$\n\n$$\n\\frac{1}{\\sqrt{{11^2 +16.3849^2}}}\\begin{bmatrix}\n11 \\\\ -16.3849\n\\end{bmatrix}= \\begin{bmatrix}\n0.5574 \\\\ -0.8303\n\\end{bmatrix} \n$$\n\n$\\Rightarrow$ $\\lambda_2$ $e_2$ (Right singular vector) =\n\n$$\n\\begin{bmatrix}\n0.8303 \\\\ 0.5574\n\\end{bmatrix} \n$$\n\n### Derive The new dataset\n\n**First Principal Component (PC1)**\n\n$$\nP_{11} = e_1^T \\times \n\\begin{bmatrix}\n4-mean(x) \\\\ 11 -mean(y)\n\\end{bmatrix}\n = \\begin{bmatrix}\n0.5574 & -0.8303 \\\\\n\\end{bmatrix} \n\\begin{bmatrix}\n4-8 \\\\ 11-8.5\n\\end{bmatrix} =-4.3052 \n$$\n\n$$\nP_{12} = e_1^T \\times \n\\begin{bmatrix}\n8-mean(x) \\\\ 4 -mean(y)\n\\end{bmatrix}\n = \\begin{bmatrix}\n0.5574 & -0.8303 \\\\\n\\end{bmatrix} \n\\begin{bmatrix}\n8-8 \\\\ 4-8.5\n\\end{bmatrix} =3.7361 \n$$\n\n$$\nP_{13} = e_1^T \\times \n\\begin{bmatrix}\n13-mean(x) \\\\ 5 -mean(y)\n\\end{bmatrix}\n = \\begin{bmatrix}\n0.5574 & -0.8303 \\\\\n\\end{bmatrix} \n\\begin{bmatrix}\n13-8 \\\\ 5-8.5\n\\end{bmatrix}= 5.6928\n$$\n\n$$\nP_{14}= e_1^T \\times \n\\begin{bmatrix}\n7-mean(x) \\\\ 14 -mean(y)\n\\end{bmatrix}\n = \\begin{bmatrix}\n0.5574 & -0.8303 \\\\\n\\end{bmatrix} \n\\begin{bmatrix}\n7-8 \\\\ 14-8.5\n\\end{bmatrix} = -5.1238\n$$\n\n<br>\n\n**The new dataset (Left singular vector)**\n\n|         | **Student 1** | **Student 2** | **Student 3** | **Student 4** |\n|:-------:|:-------------:|:-------------:|:-------------:|:-------------:|\n| **PC1** |  **-4.3052**  |  **3.7361**   |  **5.6928**   |  **-5.1238**  |\n\n### Verifying and visualizing the results\n\nUsing the factoextra @factoextra, tidyverse @tidyverse, and kableExtra @kableExtra packages, we can easily visualize the results of this analysis.\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-paper lightable-hover\" style='font-family: \"Arial Narrow\", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Dataframe structure</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Student </th>\n   <th style=\"text-align:left;\"> BasicStats </th>\n   <th style=\"text-align:left;\"> AdvancedStats </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> 4 </td>\n   <td style=\"text-align:left;\"> 11 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:left;\"> 8 </td>\n   <td style=\"text-align:left;\"> 4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:left;\"> 13 </td>\n   <td style=\"text-align:left;\"> 5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4 </td>\n   <td style=\"text-align:left;\"> 7 </td>\n   <td style=\"text-align:left;\"> 14 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-paper lightable-hover\" style='font-family: \"Arial Narrow\", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Importance of components</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:left;\"> PC1 </th>\n   <th style=\"text-align:left;\"> PC2 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Standard deviation </td>\n   <td style=\"text-align:left;\"> 1.270042 </td>\n   <td style=\"text-align:left;\"> 0.6220884 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Proportion of Variance </td>\n   <td style=\"text-align:left;\"> 0.806500 </td>\n   <td style=\"text-align:left;\"> 0.1935000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Cumulative Proportion </td>\n   <td style=\"text-align:left;\"> 0.806500 </td>\n   <td style=\"text-align:left;\"> 1.0000000 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n::: {.cell-output-display}\n![](examples_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](examples_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n:::\n\n\n### Results\n\nThe first principal component of the data captures 80.7% of the variation (or information) while reducing the dimensionality of the dataset from 2 variables to 1. Small datasets such as this make the hand-calculation of principal components feasible and easy to follow, but the strengths of PCA are especially evident when software is used to enable principal component analysis for large datasets. In the next example, we demonstrate how PCA can be used with a large dataset using the R programming language.\n\n## PCA on a large dataset using R\n\nFor this application of PCA, the Abalone dataset from the UCI Machine Learning Repository is used @misc_abalone_1. This dataset contain 4177 observations of 9 variables which record characteristics of each abalone including sex, length, diameter, height, weights, and the number of rings. The variables, apart from sex, are continuous and correlated making the dataset an ideal candidate for demonstrating dimensionality reduction via PCA.\n\n### Libraries\n\nFirst, the appropriate and necessary libraries are loaded in R. These provide the functions which serve as the backbone of the analysis, handling the computational aspects of PCA as well as visualizing the results.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load necessary libraries\nlibrary(corrplot) #for plotting the correlation matrix\nlibrary(summarytools) #produces summary stats\n```\n:::\n\n\n### Data Preparation\n\nThe dataset contains 9 variables with 1 categorical variable and 8 numeric variables. The dataset contains no missing values. For this example in applying principal component analysis, we exclude the categorical variable 'Sex' and focus the PCA on the numerical dimensions of the Abalone. For analyses involving a mix of numeric and non-numeric variables other factor analysis techniques can be used, such as factor analysis of mixed data @pages2014multiple.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load dataset\nabalone <- read.csv('./abalone/abalone.csv')\n\ndata_desc = descr(abalone, plain.ascii = FALSE, headings = FALSE) # descriptive statistics for the dataset\n\ndata_desc %>%\n  kbl(align= 'l') %>%\n  kable_paper(\"hover\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-paper lightable-hover\" style='font-family: \"Arial Narrow\", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:left;\"> Diameter </th>\n   <th style=\"text-align:left;\"> Height </th>\n   <th style=\"text-align:left;\"> Length </th>\n   <th style=\"text-align:left;\"> Rings </th>\n   <th style=\"text-align:left;\"> Shell_weight </th>\n   <th style=\"text-align:left;\"> Shucked_weight </th>\n   <th style=\"text-align:left;\"> Viscera_weight </th>\n   <th style=\"text-align:left;\"> Whole_weight </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Mean </td>\n   <td style=\"text-align:left;\"> 0.4078813 </td>\n   <td style=\"text-align:left;\"> 0.1395164 </td>\n   <td style=\"text-align:left;\"> 0.5239921 </td>\n   <td style=\"text-align:left;\"> 9.9336845 </td>\n   <td style=\"text-align:left;\"> 0.2388309 </td>\n   <td style=\"text-align:left;\"> 0.3593675 </td>\n   <td style=\"text-align:left;\"> 0.1805936 </td>\n   <td style=\"text-align:left;\"> 0.8287422 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Std.Dev </td>\n   <td style=\"text-align:left;\"> 0.0992399 </td>\n   <td style=\"text-align:left;\"> 0.0418271 </td>\n   <td style=\"text-align:left;\"> 0.1200929 </td>\n   <td style=\"text-align:left;\"> 3.2241690 </td>\n   <td style=\"text-align:left;\"> 0.1392027 </td>\n   <td style=\"text-align:left;\"> 0.2219629 </td>\n   <td style=\"text-align:left;\"> 0.1096143 </td>\n   <td style=\"text-align:left;\"> 0.4903890 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Min </td>\n   <td style=\"text-align:left;\"> 0.0550000 </td>\n   <td style=\"text-align:left;\"> 0.0000000 </td>\n   <td style=\"text-align:left;\"> 0.0750000 </td>\n   <td style=\"text-align:left;\"> 1.0000000 </td>\n   <td style=\"text-align:left;\"> 0.0015000 </td>\n   <td style=\"text-align:left;\"> 0.0010000 </td>\n   <td style=\"text-align:left;\"> 0.0005000 </td>\n   <td style=\"text-align:left;\"> 0.0020000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Q1 </td>\n   <td style=\"text-align:left;\"> 0.3500000 </td>\n   <td style=\"text-align:left;\"> 0.1150000 </td>\n   <td style=\"text-align:left;\"> 0.4500000 </td>\n   <td style=\"text-align:left;\"> 8.0000000 </td>\n   <td style=\"text-align:left;\"> 0.1300000 </td>\n   <td style=\"text-align:left;\"> 0.1860000 </td>\n   <td style=\"text-align:left;\"> 0.0935000 </td>\n   <td style=\"text-align:left;\"> 0.4415000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Median </td>\n   <td style=\"text-align:left;\"> 0.4250000 </td>\n   <td style=\"text-align:left;\"> 0.1400000 </td>\n   <td style=\"text-align:left;\"> 0.5450000 </td>\n   <td style=\"text-align:left;\"> 9.0000000 </td>\n   <td style=\"text-align:left;\"> 0.2340000 </td>\n   <td style=\"text-align:left;\"> 0.3360000 </td>\n   <td style=\"text-align:left;\"> 0.1710000 </td>\n   <td style=\"text-align:left;\"> 0.7995000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Q3 </td>\n   <td style=\"text-align:left;\"> 0.4800000 </td>\n   <td style=\"text-align:left;\"> 0.1650000 </td>\n   <td style=\"text-align:left;\"> 0.6150000 </td>\n   <td style=\"text-align:left;\"> 11.0000000 </td>\n   <td style=\"text-align:left;\"> 0.3290000 </td>\n   <td style=\"text-align:left;\"> 0.5020000 </td>\n   <td style=\"text-align:left;\"> 0.2530000 </td>\n   <td style=\"text-align:left;\"> 1.1530000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Max </td>\n   <td style=\"text-align:left;\"> 0.6500000 </td>\n   <td style=\"text-align:left;\"> 1.1300000 </td>\n   <td style=\"text-align:left;\"> 0.8150000 </td>\n   <td style=\"text-align:left;\"> 29.0000000 </td>\n   <td style=\"text-align:left;\"> 1.0050000 </td>\n   <td style=\"text-align:left;\"> 1.4880000 </td>\n   <td style=\"text-align:left;\"> 0.7600000 </td>\n   <td style=\"text-align:left;\"> 2.8255000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> MAD </td>\n   <td style=\"text-align:left;\"> 0.0963690 </td>\n   <td style=\"text-align:left;\"> 0.0370650 </td>\n   <td style=\"text-align:left;\"> 0.1186080 </td>\n   <td style=\"text-align:left;\"> 2.9652000 </td>\n   <td style=\"text-align:left;\"> 0.1475187 </td>\n   <td style=\"text-align:left;\"> 0.2349921 </td>\n   <td style=\"text-align:left;\"> 0.1178667 </td>\n   <td style=\"text-align:left;\"> 0.5285469 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> IQR </td>\n   <td style=\"text-align:left;\"> 0.1300000 </td>\n   <td style=\"text-align:left;\"> 0.0500000 </td>\n   <td style=\"text-align:left;\"> 0.1650000 </td>\n   <td style=\"text-align:left;\"> 3.0000000 </td>\n   <td style=\"text-align:left;\"> 0.1990000 </td>\n   <td style=\"text-align:left;\"> 0.3160000 </td>\n   <td style=\"text-align:left;\"> 0.1595000 </td>\n   <td style=\"text-align:left;\"> 0.7115000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> CV </td>\n   <td style=\"text-align:left;\"> 0.2433058 </td>\n   <td style=\"text-align:left;\"> 0.2998003 </td>\n   <td style=\"text-align:left;\"> 0.2291884 </td>\n   <td style=\"text-align:left;\"> 0.3245693 </td>\n   <td style=\"text-align:left;\"> 0.5828504 </td>\n   <td style=\"text-align:left;\"> 0.6176489 </td>\n   <td style=\"text-align:left;\"> 0.6069664 </td>\n   <td style=\"text-align:left;\"> 0.5917269 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Skewness </td>\n   <td style=\"text-align:left;\"> -0.6087607 </td>\n   <td style=\"text-align:left;\"> 3.1265706 </td>\n   <td style=\"text-align:left;\"> -0.6394138 </td>\n   <td style=\"text-align:left;\"> 1.1133019 </td>\n   <td style=\"text-align:left;\"> 0.6204809 </td>\n   <td style=\"text-align:left;\"> 0.7185815 </td>\n   <td style=\"text-align:left;\"> 0.5914271 </td>\n   <td style=\"text-align:left;\"> 0.5305773 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> SE.Skewness </td>\n   <td style=\"text-align:left;\"> 0.0378868 </td>\n   <td style=\"text-align:left;\"> 0.0378868 </td>\n   <td style=\"text-align:left;\"> 0.0378868 </td>\n   <td style=\"text-align:left;\"> 0.0378868 </td>\n   <td style=\"text-align:left;\"> 0.0378868 </td>\n   <td style=\"text-align:left;\"> 0.0378868 </td>\n   <td style=\"text-align:left;\"> 0.0378868 </td>\n   <td style=\"text-align:left;\"> 0.0378868 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Kurtosis </td>\n   <td style=\"text-align:left;\"> -0.0482711 </td>\n   <td style=\"text-align:left;\"> 75.8953091 </td>\n   <td style=\"text-align:left;\"> 0.0616411 </td>\n   <td style=\"text-align:left;\"> 2.3239123 </td>\n   <td style=\"text-align:left;\"> 0.5281636 </td>\n   <td style=\"text-align:left;\"> 0.5912553 </td>\n   <td style=\"text-align:left;\"> 0.0809994 </td>\n   <td style=\"text-align:left;\"> -0.0264756 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> N.Valid </td>\n   <td style=\"text-align:left;\"> 4177.0000000 </td>\n   <td style=\"text-align:left;\"> 4177.0000000 </td>\n   <td style=\"text-align:left;\"> 4177.0000000 </td>\n   <td style=\"text-align:left;\"> 4177.0000000 </td>\n   <td style=\"text-align:left;\"> 4177.0000000 </td>\n   <td style=\"text-align:left;\"> 4177.0000000 </td>\n   <td style=\"text-align:left;\"> 4177.0000000 </td>\n   <td style=\"text-align:left;\"> 4177.0000000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Pct.Valid </td>\n   <td style=\"text-align:left;\"> 100.0000000 </td>\n   <td style=\"text-align:left;\"> 100.0000000 </td>\n   <td style=\"text-align:left;\"> 100.0000000 </td>\n   <td style=\"text-align:left;\"> 100.0000000 </td>\n   <td style=\"text-align:left;\"> 100.0000000 </td>\n   <td style=\"text-align:left;\"> 100.0000000 </td>\n   <td style=\"text-align:left;\"> 100.0000000 </td>\n   <td style=\"text-align:left;\"> 100.0000000 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nThe summary statistics show the differences in measurement between variables, with some variables such as diameter and viscera weight having small ranges and others, namely rings, having relatively large ranges. For this reason, scaling of the variables is a crucial step in PCA to ensure results accurately capture the variance in the data.\n\n### Feature Scaling\n\nStandardization ensures all variables, also called features, are on the same scale, and the scale function allows us to center the data to a mean of 0 and variance of 1. This ensures no single feature has an outsized effect during the principal component analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select only the numeric variables \nabalone = select_if(abalone, is.numeric)\n\n# Standardization of numerical features\nabalone_sc <- scale(abalone, center = TRUE, scale = TRUE)\n\nsc_sum = summary(abalone_sc)\n\nkbl(sc_sum, align= 'l') %>%\n  kable_paper(\"hover\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-paper lightable-hover\" style='font-family: \"Arial Narrow\", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:left;\">     Length </th>\n   <th style=\"text-align:left;\">    Diameter </th>\n   <th style=\"text-align:left;\">     Height </th>\n   <th style=\"text-align:left;\">  Whole_weight </th>\n   <th style=\"text-align:left;\"> Shucked_weight </th>\n   <th style=\"text-align:left;\"> Viscera_weight </th>\n   <th style=\"text-align:left;\">  Shell_weight </th>\n   <th style=\"text-align:left;\">     Rings </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:left;\"> Min.   :-3.7387 </td>\n   <td style=\"text-align:left;\"> Min.   :-3.5558 </td>\n   <td style=\"text-align:left;\"> Min.   :-3.33555 </td>\n   <td style=\"text-align:left;\"> Min.   :-1.68589 </td>\n   <td style=\"text-align:left;\"> Min.   :-1.6145 </td>\n   <td style=\"text-align:left;\"> Min.   :-1.64298 </td>\n   <td style=\"text-align:left;\"> Min.   :-1.7049 </td>\n   <td style=\"text-align:left;\"> Min.   :-2.7708 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:left;\"> 1st Qu.:-0.6161 </td>\n   <td style=\"text-align:left;\"> 1st Qu.:-0.5832 </td>\n   <td style=\"text-align:left;\"> 1st Qu.:-0.58614 </td>\n   <td style=\"text-align:left;\"> 1st Qu.:-0.78966 </td>\n   <td style=\"text-align:left;\"> 1st Qu.:-0.7811 </td>\n   <td style=\"text-align:left;\"> 1st Qu.:-0.79455 </td>\n   <td style=\"text-align:left;\"> 1st Qu.:-0.7818 </td>\n   <td style=\"text-align:left;\"> 1st Qu.:-0.5997 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:left;\"> Median : 0.1749 </td>\n   <td style=\"text-align:left;\"> Median : 0.1725 </td>\n   <td style=\"text-align:left;\"> Median : 0.01156 </td>\n   <td style=\"text-align:left;\"> Median :-0.05963 </td>\n   <td style=\"text-align:left;\"> Median :-0.1053 </td>\n   <td style=\"text-align:left;\"> Median :-0.08752 </td>\n   <td style=\"text-align:left;\"> Median :-0.0347 </td>\n   <td style=\"text-align:left;\"> Median :-0.2896 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:left;\"> Mean   : 0.0000 </td>\n   <td style=\"text-align:left;\"> Mean   : 0.0000 </td>\n   <td style=\"text-align:left;\"> Mean   : 0.00000 </td>\n   <td style=\"text-align:left;\"> Mean   : 0.00000 </td>\n   <td style=\"text-align:left;\"> Mean   : 0.0000 </td>\n   <td style=\"text-align:left;\"> Mean   : 0.00000 </td>\n   <td style=\"text-align:left;\"> Mean   : 0.0000 </td>\n   <td style=\"text-align:left;\"> Mean   : 0.0000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:left;\"> 3rd Qu.: 0.7578 </td>\n   <td style=\"text-align:left;\"> 3rd Qu.: 0.7267 </td>\n   <td style=\"text-align:left;\"> 3rd Qu.: 0.60926 </td>\n   <td style=\"text-align:left;\"> 3rd Qu.: 0.66123 </td>\n   <td style=\"text-align:left;\"> 3rd Qu.: 0.6426 </td>\n   <td style=\"text-align:left;\"> 3rd Qu.: 0.66056 </td>\n   <td style=\"text-align:left;\"> 3rd Qu.: 0.6478 </td>\n   <td style=\"text-align:left;\"> 3rd Qu.: 0.3307 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:left;\"> Max.   : 2.4232 </td>\n   <td style=\"text-align:left;\"> Max.   : 2.4397 </td>\n   <td style=\"text-align:left;\"> Max.   :23.68045 </td>\n   <td style=\"text-align:left;\"> Max.   : 4.07178 </td>\n   <td style=\"text-align:left;\"> Max.   : 5.0848 </td>\n   <td style=\"text-align:left;\"> Max.   : 5.28587 </td>\n   <td style=\"text-align:left;\"> Max.   : 5.5040 </td>\n   <td style=\"text-align:left;\"> Max.   : 5.9136 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nViewing the data after scaling and centering, values greater than 3 or less than -3 represent outliers more than 3 standard deviations from the mean. Based on the ranges of the variables, we should view a boxplot of the data to further investigate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot a boxplot to visualize potential outliers\npar(mar=c(4, 8, 4, 4))\nboxplot(abalone_sc, col = \"steelblue\", main = \"Visualization of scaled and centered data\", horizontal = TRUE, las = 1)\n```\n\n::: {.cell-output-display}\n![](examples_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nAre there enough outliers to be a cause for concern? We can see how many lie outside of the third standard deviation of the data for each variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nouts = colSums(abalone_sc > 3 | abalone_sc < -3)\n\nkbl(outs, col.names = ('Outliers'), align = 'l') %>%\n  kable_paper(\"hover\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-paper lightable-hover\" style='font-family: \"Arial Narrow\", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:left;\"> Outliers </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Length </td>\n   <td style=\"text-align:left;\"> 15 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Diameter </td>\n   <td style=\"text-align:left;\"> 13 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Height </td>\n   <td style=\"text-align:left;\"> 5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Whole_weight </td>\n   <td style=\"text-align:left;\"> 19 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Shucked_weight </td>\n   <td style=\"text-align:left;\"> 37 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Viscera_weight </td>\n   <td style=\"text-align:left;\"> 22 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Shell_weight </td>\n   <td style=\"text-align:left;\"> 27 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Rings </td>\n   <td style=\"text-align:left;\"> 62 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nOf the 4177 observations, at most 62 in a single variable (Rings) are outliers. The tolerance for outliers will differ depending on the investigation, but for our illustrative purposes this number is well within tolerance for principal component analysis.\n\nLastly, we can investigate the correlation among the variables. PCA is best used with linearly correlated data. If the data is not correlated, the results of PCA will be less meaningful.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate correlations and round to 2 digits\nabalone_corr <- cor(abalone_sc)\ncorrplot(abalone_corr, method=\"number\")\n```\n\n::: {.cell-output-display}\n![](examples_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nOur scaled and centered data has strong linear correlations and contains a relatively small number of outliers. We can now calculate the principal components of the dataset.\n\n### PCA via Singular Value Decomposition\n\nThe prcomp() function from the stats package in R @R performs principal component analysis on a dataset using the singular value decomposition method, which utilizes the covariance matrix of the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Apply PCA using prcomp()\nabalone_pca <- prcomp(abalone_sc)\n\nsum_pca = as.data.frame(summary(abalone_pca)$importance)\n\nkbl(sum_pca, align= 'l', caption = \"Importance of components\") %>%\n  kable_paper(\"hover\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-paper lightable-hover\" style='font-family: \"Arial Narrow\", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Importance of components</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:left;\"> PC1 </th>\n   <th style=\"text-align:left;\"> PC2 </th>\n   <th style=\"text-align:left;\"> PC3 </th>\n   <th style=\"text-align:left;\"> PC4 </th>\n   <th style=\"text-align:left;\"> PC5 </th>\n   <th style=\"text-align:left;\"> PC6 </th>\n   <th style=\"text-align:left;\"> PC7 </th>\n   <th style=\"text-align:left;\"> PC8 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Standard deviation </td>\n   <td style=\"text-align:left;\"> 2.590838 </td>\n   <td style=\"text-align:left;\"> 0.8340342 </td>\n   <td style=\"text-align:left;\"> 0.508373 </td>\n   <td style=\"text-align:left;\"> 0.4074185 </td>\n   <td style=\"text-align:left;\"> 0.2914613 </td>\n   <td style=\"text-align:left;\"> 0.251938 </td>\n   <td style=\"text-align:left;\"> 0.1126684 </td>\n   <td style=\"text-align:left;\"> 0.0799895 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Proportion of Variance </td>\n   <td style=\"text-align:left;\"> 0.839050 </td>\n   <td style=\"text-align:left;\"> 0.0869500 </td>\n   <td style=\"text-align:left;\"> 0.032310 </td>\n   <td style=\"text-align:left;\"> 0.0207500 </td>\n   <td style=\"text-align:left;\"> 0.0106200 </td>\n   <td style=\"text-align:left;\"> 0.007930 </td>\n   <td style=\"text-align:left;\"> 0.0015900 </td>\n   <td style=\"text-align:left;\"> 0.0008000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Cumulative Proportion </td>\n   <td style=\"text-align:left;\"> 0.839050 </td>\n   <td style=\"text-align:left;\"> 0.9260100 </td>\n   <td style=\"text-align:left;\"> 0.958310 </td>\n   <td style=\"text-align:left;\"> 0.9790600 </td>\n   <td style=\"text-align:left;\"> 0.9896800 </td>\n   <td style=\"text-align:left;\"> 0.997610 </td>\n   <td style=\"text-align:left;\"> 0.9992000 </td>\n   <td style=\"text-align:left;\"> 1.0000000 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Principal Component scores vector\npc_scores <- abalone_pca$x\n\n# Std Deviation of Components\ncomponent_sdev <- abalone_pca$sdev\n\n# Eigenvector or Loadings\neigenvector <- abalone_pca$rotation\n\n# Mean of variables\ncomponent_mean <- abalone_pca$center \n\n# Scaling factor of Variables\ncomponent_scale <- abalone_pca$scale\n\n# Proportion of variance explained by each PC\nvariance_explained <- component_sdev^2 / sum(component_sdev^2)\n\n# Cumulative proportion of variance explained\ncumulative_variance_explained <- cumsum(variance_explained)\n\n# Retain components that explain a percentage of the variance\nnum_components <- which(cumulative_variance_explained >= 0.92)[1]\n\n# Select the desired number of principal components\nselected_pcs <- pc_scores[, 1:num_components]\n```\n:::\n\n\nThe first 2 principal components alone explain 92% of the variance in the data.\n\n#### Loading of First Two Components\n\nThe loading are the weights assigned to each variable for that particular principal component.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Access the loadings for the first two principal components\nloadings_first_two_components <- eigenvector[, 1:2]\n\n# Print the loadings for the first two principal components\n\nkbl(loadings_first_two_components, align= 'l', caption = \"Loadings for the first two principal components\") %>%\n  kable_paper(\"hover\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-paper lightable-hover\" style='font-family: \"Arial Narrow\", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Loadings for the first two principal components</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:left;\"> PC1 </th>\n   <th style=\"text-align:left;\"> PC2 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Length </td>\n   <td style=\"text-align:left;\"> 0.3721385 </td>\n   <td style=\"text-align:left;\"> 0.0682827 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Diameter </td>\n   <td style=\"text-align:left;\"> 0.3730941 </td>\n   <td style=\"text-align:left;\"> 0.0400480 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Height </td>\n   <td style=\"text-align:left;\"> 0.3400268 </td>\n   <td style=\"text-align:left;\"> -0.0704631 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Whole_weight </td>\n   <td style=\"text-align:left;\"> 0.3783075 </td>\n   <td style=\"text-align:left;\"> 0.1373462 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Shucked_weight </td>\n   <td style=\"text-align:left;\"> 0.3624545 </td>\n   <td style=\"text-align:left;\"> 0.2988399 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Viscera_weight </td>\n   <td style=\"text-align:left;\"> 0.3685578 </td>\n   <td style=\"text-align:left;\"> 0.1729785 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Shell_weight </td>\n   <td style=\"text-align:left;\"> 0.3707578 </td>\n   <td style=\"text-align:left;\"> -0.0454004 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Rings </td>\n   <td style=\"text-align:left;\"> 0.2427128 </td>\n   <td style=\"text-align:left;\"> -0.9212039 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n#### PCA - Elements\n\nThe values in **`abalone_pca$x`** are the coordinates of each observation in the new principal component space. These coordinates are the scores for each observation along each principal component. The eigenvectors of the covariance or correlation matrix of the data represent the directions of maximum variance in the dataset.\n\n### Visualization\n\n#### Scree Plot - Cumulative Variance Explained\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_eig(abalone_pca, addlabels = TRUE)\n```\n\n::: {.cell-output-display}\n![](examples_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nThe scree plot visualizes the variance captured by each PC. PC1 explains 83.9% of the variance, and PC2 explains 8.7% variance.\n\n#### Biplot\n\nThe correlation between a variable and a principal component is used as the coordinates of the variable on the PC, shown as dimensions on the biplot. Dim1 corresponds to PC1, and Dim2 to PC2. The representation of variables differs from the plot of the observations: The observations are represented by their projections, but the variables are represented by their correlations @abdi2010principal.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_pca_biplot(abalone_pca, label = \"var\", alpha.ind = \"contrib\", col.var = \"blue\", repel = TRUE)\n```\n\n::: {.cell-output-display}\n![](examples_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n#### Variable Contribution\n\nTop variable contribution for the first two principal components.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Contributions of variables to PC1\npc2_contribution <- fviz_contrib(abalone_pca, choice = \"var\", axes = 1, top = 20)\n\n# Modify the theme to rotate X-axis labels to 90 degrees\npc2_contribution +\n  theme(\n    axis.text.x = element_text(angle = 0),\n    plot.title = element_text(hjust = 0)  # horizontal justification\n  ) +\n  coord_flip() +\n  labs(title = \"Contribution of Variables to PC1\",\n       y = \"Percentage Contribution\",\n       x = \"\",\n       caption = \"PC1 explains 83.9% of the variance\") +\n  scale_y_continuous(labels = scales::percent_format(scale = 1,\n                                                     accuracy = 1))\n```\n\n::: {.cell-output-display}\n![](examples_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Contributions of variables to PC2\npc2_contribution <- fviz_contrib(abalone_pca, choice = \"var\", axes = 2, top = 12)\n\n# Modify the theme to rotate X-axis labels to 90 degrees\npc2_contribution +\n  theme(\n    axis.text.x = element_text(angle = 0),\n    plot.title = element_text(hjust = 0)  # horizontal justification\n  ) +\n  coord_flip() +\n  labs(title = \"Contribution of Variables to PC2\",\n       y = \"Percentage Contribution\",\n       x = \"\",\n       caption = \"PC2 explains 8.7% of the variance\") +\n  scale_y_continuous(labels = scales::percent_format(scale = 1,\n                                                     accuracy = 1))\n```\n\n::: {.cell-output-display}\n![](examples_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n:::\n\n\n### Results\n\nThe first principal component captures 83.9% of the variance in the data. This linear combination has relatively equal loadings for whole weight, diameter, length, shell weight, viscera weight, and shucked weight, with height and rings having lower loadings. The second principal component is mostly influenced by the variable rings which makes up over 80% of the contribution to PC2. The biplot is an effective visualization of how each variable contributes to PC1, or dimension 1 on the graph, and PC2, or dimension 2 on the graph. The length and direction of each vector represent the contribution of each variable to the principal components; whole weight and rings are the longest, representing the largest contributions to PC1 and PC2 respectively.\n\nPCA is primarily an exploratory tool, which allows us to visualize high-dimensional data in lower dimensions as shown above in the biplot and accompanying scree plot. These PCs can be used to explore data in other ways, such as looking for trends and patterns in the data or identifying clusters and outliers. In the formal analysis in the following chapter, the applications of PCA are further explored through the development of a regression model on the principal components of a dataset.\n",
    "supporting": [
      "examples_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}